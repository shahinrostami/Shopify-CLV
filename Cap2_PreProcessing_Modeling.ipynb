{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of this notebook:\n",
    "### 1. Preprocesses the data to prepare for modeling\n",
    "### 2. Modeling using a number of different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Preprocessing\n",
    "We get the data ready to model by dropping some features, creating dummy variables for catagorical features, and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "os.chdir(\"C:\\Springboard\\Github\\Capstone2_cust\\Intermediate_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>first_order</th>\n",
       "      <th>server</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Source</th>\n",
       "      <th>Area_Code</th>\n",
       "      <th>Ship_Zip</th>\n",
       "      <th>lead_sku</th>\n",
       "      <th>weekday</th>\n",
       "      <th>mon</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>first_it_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-26 21:44:16+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>404</td>\n",
       "      <td>30087</td>\n",
       "      <td>other</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-11-26 20:52:08+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>845</td>\n",
       "      <td>12545</td>\n",
       "      <td>other</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-26 18:12:04+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>262</td>\n",
       "      <td>53402</td>\n",
       "      <td>ROUTEINS10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-07 18:14:49+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>617</td>\n",
       "      <td>01983</td>\n",
       "      <td>BEM1003</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-07 18:05:28+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>740</td>\n",
       "      <td>43143</td>\n",
       "      <td>other</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-07 03:45:52+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>701</td>\n",
       "      <td>58801</td>\n",
       "      <td>BES1006</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.623249</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-06 22:00:54+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>754</td>\n",
       "      <td>33026</td>\n",
       "      <td>BEM6001</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.434569</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-06 20:22:25+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>unknown</td>\n",
       "      <td>01880</td>\n",
       "      <td>BES5001</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.342423</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-06 19:59:05+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>617</td>\n",
       "      <td>01880</td>\n",
       "      <td>BEM1007</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-06 19:14:49+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>626</td>\n",
       "      <td>92887</td>\n",
       "      <td>BEM1007</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.563955</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_total  Marketing_first  first_items               first_order  \\\n",
       "1        145.58                1            2 2019-11-26 21:44:16+00:00   \n",
       "2        137.55                0            5 2019-11-26 20:52:08+00:00   \n",
       "3         22.98                1            2 2019-11-26 18:12:04+00:00   \n",
       "4         28.00                0            1 2019-08-07 18:14:49+00:00   \n",
       "5         12.00                1            1 2019-08-07 18:05:28+00:00   \n",
       "6         42.00                0            2 2019-08-07 03:45:52+00:00   \n",
       "7         27.20                1            1 2019-08-06 22:00:54+00:00   \n",
       "8         22.00                1            2 2019-08-06 20:22:25+00:00   \n",
       "9        100.00                1            5 2019-08-06 19:59:05+00:00   \n",
       "10        36.64                1            2 2019-08-06 19:14:49+00:00   \n",
       "\n",
       "    server  Vendor Source Area_Code Ship_Zip    lead_sku    weekday       mon  \\\n",
       "1   custom     1.0    web       404    30087       other    Tuesday  November   \n",
       "2   custom     1.0    web       845    12545       other    Tuesday  November   \n",
       "3   custom     1.0    web       262    53402  ROUTEINS10    Tuesday  November   \n",
       "4   custom     0.0    web       617    01983     BEM1003  Wednesday    August   \n",
       "5   custom     0.0    web       740    43143       other  Wednesday    August   \n",
       "6   custom     0.0    web       701    58801     BES1006  Wednesday    August   \n",
       "7   custom     0.0    web       754    33026     BEM6001    Tuesday    August   \n",
       "8   custom     0.0    web   unknown    01880     BES5001    Tuesday    August   \n",
       "9   custom     0.0    web       617    01880     BEM1007    Tuesday    August   \n",
       "10  custom     0.0    web       626    92887     BEM1007    Tuesday    August   \n",
       "\n",
       "    first_tot_lg  first_it_lg  \n",
       "1       2.163102      0.30103  \n",
       "2       2.138461      0.69897  \n",
       "3       1.361350      0.30103  \n",
       "4       1.447158      0.00000  \n",
       "5       1.079181      0.00000  \n",
       "6       1.623249      0.30103  \n",
       "7       1.434569      0.00000  \n",
       "8       1.342423      0.30103  \n",
       "9       2.000000      0.69897  \n",
       "10      1.563955      0.30103  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load picked version of X\n",
    "X = pickle.load(open(\"X1.pkl\", \"rb\"))\n",
    "# look at the first 10 rows of this file\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. Let's review what each column means: <br>\n",
    "- first_total: total $ spend on first order <br>\n",
    "- Marketing_first: whether they accept marketing on the first order <br>\n",
    "- first_items: number of items on first order <br>\n",
    "- first_order: date-time of first order <br>\n",
    "- server: domain name of the customer email server <br>\n",
    "- vendor: 0 = first order from company; 1 = first order from outside source <br>\n",
    "- Source: web or iphone\n",
    "- Area_Code: area code of order placed\n",
    "- Ship_Zip: zip code of shipping address\n",
    "- lead_sku: name of SKU that was lead item on purchase\n",
    "- weekday: day of week first order was placed\n",
    "- mon: month that first order was placed\n",
    "- first_tot_lg: log of first order total\n",
    "- first_it_lg: log of number of items in first order <br>\n",
    "<br>\n",
    "The values for some of these catagorical features need to be converted to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "web        33949\n",
       "1356615     5423\n",
       "294517       273\n",
       "457101        67\n",
       "580111        16\n",
       "412739         2\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop first order item log\n",
    "X.drop('first_it_lg', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39730 entries, 1 to 39770\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   first_total      39730 non-null  float64            \n",
      " 1   Marketing_first  39730 non-null  int64              \n",
      " 2   first_items      39730 non-null  int64              \n",
      " 3   first_order      39730 non-null  datetime64[ns, UTC]\n",
      " 4   server           39730 non-null  object             \n",
      " 5   Vendor           39730 non-null  float64            \n",
      " 6   Source           39730 non-null  object             \n",
      " 7   Area_Code        39730 non-null  object             \n",
      " 8   Ship_Zip         39730 non-null  object             \n",
      " 9   lead_sku         39730 non-null  object             \n",
      " 10  weekday          39730 non-null  object             \n",
      " 11  mon              39730 non-null  object             \n",
      " 12  first_tot_lg     39730 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(3), int64(2), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traditional regression can't handle date-time, so we'll drop that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date-time\n",
    "X.drop('first_order', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features that need dummy variables:\n",
    "- server\n",
    "- source\n",
    "- Area_Code\n",
    "- Ship_Zip\n",
    "- lead_sku\n",
    "- weekday\n",
    "- mon <br>\n",
    "<br>\n",
    "Let's look at the size of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['server'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Source'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Area_Code'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is too man catagorical variables for this feature. I wonder if there are high concentrations of purchases in some zip codes that we could account for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    21387\n",
       "949          273\n",
       "714          204\n",
       "720          161\n",
       "760          155\n",
       "310          148\n",
       "214          144\n",
       "512          144\n",
       "817          139\n",
       "801          135\n",
       "757          132\n",
       "917          131\n",
       "208          131\n",
       "503          130\n",
       "909          130\n",
       "916          129\n",
       "704          129\n",
       "360          128\n",
       "619          127\n",
       "303          121\n",
       "Name: Area_Code, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Area_Code'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 40k customers, so the largest area code makes up 0.68% of total orders. I think this feature is too small and would add unnecessary dimensions. We will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('Area_Code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15930"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Ship_Zip'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is way too many features. Unless they are very concentrated in a few zip codes, we'll drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92688      48\n",
       "92692      48\n",
       "unknown    48\n",
       "92691      46\n",
       "28532      41\n",
       "92694      40\n",
       "92630      39\n",
       "92627      38\n",
       "92656      31\n",
       "92679      29\n",
       "92677      27\n",
       "92675      25\n",
       "92672      24\n",
       "92626      23\n",
       "92592      22\n",
       "92629      22\n",
       "80013      22\n",
       "92660      21\n",
       "93551      20\n",
       "79936      20\n",
       "Name: Ship_Zip, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Ship_Zip'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop that feature\n",
    "X.drop('Ship_Zip', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['lead_sku'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how many variables for days of the week and month there are. This means we should see: <br>\n",
    "- server: 26\n",
    "- source: 6\n",
    "- lead_sku: 26\n",
    "- weekday: 7\n",
    "- mon: 12 <br>\n",
    "- total: 77 more freatures <br>\n",
    "<br>\n",
    "That seems reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy for server ##\n",
    "dfs = X['server']\n",
    "dummy_server = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('server', axis=1), dummy_server], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for Source\n",
    "dfs = X['Source']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('Source', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for lead_sku\n",
    "dfs = X['lead_sku']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('lead_sku', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for weekday\n",
    "dfs = X['weekday']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('weekday', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>aim.com</th>\n",
       "      <th>aol.com</th>\n",
       "      <th>att.net</th>\n",
       "      <th>bellsouth.net</th>\n",
       "      <th>charter.net</th>\n",
       "      <th>...</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39766</th>\n",
       "      <td>27.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.446848</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>59.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>54.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.740126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>90.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.957512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39730 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_total  Marketing_first  first_items  Vendor  first_tot_lg  \\\n",
       "1           145.58                1            2     1.0      2.163102   \n",
       "2           137.55                0            5     1.0      2.138461   \n",
       "3            22.98                1            2     1.0      1.361350   \n",
       "4            28.00                0            1     0.0      1.447158   \n",
       "5            12.00                1            1     0.0      1.079181   \n",
       "...            ...              ...          ...     ...           ...   \n",
       "39766        27.98                0            2     1.0      1.446848   \n",
       "39767        59.97                0            2     1.0      1.777934   \n",
       "39768        54.97                1            2     1.0      1.740126   \n",
       "39769        90.68                0            3     1.0      1.957512   \n",
       "39770        25.00                0            1     0.0      1.397940   \n",
       "\n",
       "       aim.com  aol.com  att.net  bellsouth.net  charter.net  ...  December  \\\n",
       "1            0        0        0              0            0  ...         0   \n",
       "2            0        0        0              0            0  ...         0   \n",
       "3            0        0        0              0            0  ...         0   \n",
       "4            0        0        0              0            0  ...         0   \n",
       "5            0        0        0              0            0  ...         0   \n",
       "...        ...      ...      ...            ...          ...  ...       ...   \n",
       "39766        0        0        0              0            0  ...         0   \n",
       "39767        0        0        0              0            0  ...         0   \n",
       "39768        0        0        0              0            0  ...         0   \n",
       "39769        0        0        0              0            0  ...         0   \n",
       "39770        0        0        0              0            0  ...         0   \n",
       "\n",
       "       February  January  July  June  March  May  November  October  September  \n",
       "1             0        0     0     0      0    0         1        0          0  \n",
       "2             0        0     0     0      0    0         1        0          0  \n",
       "3             0        0     0     0      0    0         1        0          0  \n",
       "4             0        0     0     0      0    0         0        0          0  \n",
       "5             0        0     0     0      0    0         0        0          0  \n",
       "...         ...      ...   ...   ...    ...  ...       ...      ...        ...  \n",
       "39766         0        0     0     0      0    0         0        0          1  \n",
       "39767         0        0     0     0      0    0         0        0          1  \n",
       "39768         0        0     0     0      0    0         0        0          1  \n",
       "39769         0        0     0     0      0    0         0        0          1  \n",
       "39770         0        0     0     0      0    0         0        0          1  \n",
       "\n",
       "[39730 rows x 82 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy for weekday\n",
    "dfs = X['mon']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('mon', axis=1), dummy_source], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good. Let's load Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2.163102\n",
       "2     2.138461\n",
       "3     1.361350\n",
       "4     1.447158\n",
       "5     1.079181\n",
       "6     1.623249\n",
       "7     1.434569\n",
       "8     1.342423\n",
       "9     2.000000\n",
       "10    1.563955\n",
       "Name: life_lg, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load picked version of X\n",
    "y = pickle.load(open(\"Y1.pkl\", \"rb\"))\n",
    "# look at the first 10 rows of this file\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the X values\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# let's do the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8158008483225205, 1.8162965793223824)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's quickly check that the Y means to make sure the data sets are similiar\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those look reasonably close. <br>\n",
    "<br>\n",
    "That is the end of preprocessing. Time to model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modeling\n",
    "We will try a few different models: <br>\n",
    "- Linear Regression\n",
    "- Random Forest Regressor\n",
    "- Dummy Model (assume every customer is average)\n",
    "- Gradient Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to track model performance\n",
    "perform = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first model from X-train\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50444183616.4365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted results from the first model on the X_test values\n",
    "y_pred = model.predict(X_test)\n",
    "# Mean Absolute Error\n",
    "m1_MAE = mean_absolute_error(y_test, y_pred)\n",
    "m1_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0109758020001125e+25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m1_MSE = mean_squared_error(y_test, y_pred)\n",
    "m1_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values seem extremely high. I want to look at some of the values in the model really quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10088836725.066\n"
     ]
    }
   ],
   "source": [
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems way off with linear regression. Let's see if Random Forest Regressor looks any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "m1_RMSE = m1_MSE**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Linear Regression', 'MAE':m1_MAE, 'MSE':m1_MSE, 'RMSE':m1_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a minimum sample of 40 or 1/1000th of the total number of customers\n",
    "regr = RandomForestRegressor(min_samples_leaf=40, random_state=33)\n",
    "model_rf = regr.fit(X_train,y_train)\n",
    "y_pred_rf = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18474874822669013"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "m2_MAE = mean_absolute_error(y_test, y_pred_rf)\n",
    "m2_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06807649032099493"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m2_MSE = mean_squared_error(y_test, y_pred_rf)\n",
    "m2_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2609147184828693"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m2_RMSE = m2_MSE**0.5\n",
    "m2_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is so much better! <br>\n",
    "Let's look at the importance of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_tot_lg</th>\n",
       "      <td>0.510678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_total</th>\n",
       "      <td>0.430523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November</th>\n",
       "      <td>0.011758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356615</th>\n",
       "      <td>0.007362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_items</th>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gmail.com</th>\n",
       "      <td>0.003772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December</th>\n",
       "      <td>0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing_first</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February</th>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS10</th>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April</th>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor</th>\n",
       "      <td>0.001307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yahoo.com</th>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Importance\n",
       "first_tot_lg       0.510678\n",
       "first_total        0.430523\n",
       "November           0.011758\n",
       "1356615            0.007362\n",
       "first_items        0.003863\n",
       "gmail.com          0.003772\n",
       "December           0.002964\n",
       "Marketing_first    0.002945\n",
       "January            0.002182\n",
       "July               0.002089\n",
       "February           0.001909\n",
       "ROUTEINS10         0.001543\n",
       "April              0.001373\n",
       "other              0.001326\n",
       "Vendor             0.001307\n",
       "June               0.001301\n",
       "yahoo.com          0.001148\n",
       "May                0.000947\n",
       "Monday             0.000931\n",
       "web                0.000898"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coff_m2 = pd.DataFrame(model_rf.feature_importances_, X.columns, columns=['Importance'])\n",
    "coff_m2.sort_values('Importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are good see. <br>\n",
    "We may want to use these values to eliminate some variable from the regression model, but first let's compare the RMSE and AMSE to a dummy model that just assumes very customer is average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEM1007</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msn.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optonline.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocketmail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbcglobal.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verizon.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1005</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457101</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580111</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM1009</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windstream.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlook.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aim.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES5001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charter.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cox.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellsouth.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES3003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importance\n",
       "BEM1007                0.0\n",
       "me.com                 0.0\n",
       "msn.com                0.0\n",
       "optonline.net          0.0\n",
       "rocketmail.com         0.0\n",
       "sbcglobal.net          0.0\n",
       "vendor                 0.0\n",
       "mac.com                0.0\n",
       "verizon.net            0.0\n",
       "ymail.com              0.0\n",
       "BES1005                0.0\n",
       "412739                 0.0\n",
       "457101                 0.0\n",
       "580111                 0.0\n",
       "BEM1009                0.0\n",
       "windstream.net         0.0\n",
       "live.com               0.0\n",
       "outlook.com            0.0\n",
       "aim.com                0.0\n",
       "BES5001                0.0\n",
       "att.net                0.0\n",
       "charter.net            0.0\n",
       "cox.net                0.0\n",
       "bellsouth.net          0.0\n",
       "BES3003                0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the least important values\n",
    "m2_unimportant = coff_m2.sort_values('Importance', ascending=True).head(25)\n",
    "m2_unimportant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these features have literally no importance on this Random Forest Regressor. We will use these later to drop from the features so that we can build a model that works with the important features only and doesn't waste time on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Random Forest 1', 'MAE':m2_MAE, 'MSE':m2_MSE, 'RMSE':m2_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dummy Model (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29065108266816125"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assume the model is the average of the training data (we know this value)\n",
    "y_pred_dm = np.full(y_test.size, y_train.mean())\n",
    "# Mean Absolute Error\n",
    "m3_MAE = mean_absolute_error(y_test, y_pred_dm)\n",
    "m3_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14451655741084168"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m3_MSE = mean_squared_error(y_test, y_pred_dm)\n",
    "m3_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38015333407829227"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m3_RMSE = m3_MSE**0.5\n",
    "m3_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are worse than the Random Forest Regressor, so that's a good thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11923861559542298"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference in root mean squared error between the two models\n",
    "diff = m3_RMSE - m2_RMSE\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3159476582939336"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lifetime dollar value of that difference\n",
    "10**diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is honestly not that impressive, but is still better than the dummy model. <br>\n",
    "<br>\n",
    "Let's see if we can use those results to improve the models after we try the Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Dummy Model (average)', 'MAE':m3_MAE, 'MSE':m3_MSE, 'RMSE':m3_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18474874822669013"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor\n",
    "reg_gb = GradientBoostingRegressor(min_samples_leaf=40, random_state=0)\n",
    "# fit the regressor\n",
    "model_gb = reg_gb.fit(X_train,y_train)\n",
    "# use regressor to predict on test data\n",
    "y_pred_gb = regr.predict(X_test)\n",
    "# compare test data for a score - Mean Absolute Error\n",
    "m4_MAE = mean_absolute_error(y_test, y_pred_gb)\n",
    "m4_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06807649032099493"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m4_MSE = mean_squared_error(y_test, y_pred_gb)\n",
    "m4_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2609147184828693"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m4_RMSE = m4_MSE**0.5\n",
    "m4_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are extremely good; they are very similar to the results from the Random Forest Regressor. We probably should improve these two models to get the best results. Let's look at the importance of each feature in the GB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_tot_lg</th>\n",
       "      <td>0.523446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_total</th>\n",
       "      <td>0.424205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November</th>\n",
       "      <td>0.010217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356615</th>\n",
       "      <td>0.006939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_items</th>\n",
       "      <td>0.004168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294517</th>\n",
       "      <td>0.004014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457101</th>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>0.002540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1011</th>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December</th>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September</th>\n",
       "      <td>0.001886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August</th>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.001423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February</th>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1010</th>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October</th>\n",
       "      <td>0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS10</th>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "first_tot_lg    0.523446\n",
       "first_total     0.424205\n",
       "November        0.010217\n",
       "1356615         0.006939\n",
       "first_items     0.004168\n",
       "294517          0.004014\n",
       "457101          0.002968\n",
       "July            0.002540\n",
       "BES1011         0.002495\n",
       "December        0.002075\n",
       "September       0.001886\n",
       "August          0.001499\n",
       "other           0.001423\n",
       "February        0.001276\n",
       "custom          0.001168\n",
       "BES1010         0.001147\n",
       "October         0.001008\n",
       "ROUTEINS10      0.000985\n",
       "June            0.000936\n",
       "January         0.000815"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coff_m4 = pd.DataFrame(model_gb.feature_importances_, X.columns, columns=['Importance'])\n",
    "coff_m4.sort_values('Importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEM1007</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verizon.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windstream.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yahoo.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6008</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6728</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6729</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbcglobal.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6737</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1005</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES3003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES5001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6738</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocketmail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580111</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optonline.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthlink.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charter.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellsouth.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlook.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aim.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aol.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icloud.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msn.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comcast.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importance\n",
       "BEM1007                0.0\n",
       "vendor                 0.0\n",
       "verizon.net            0.0\n",
       "windstream.net         0.0\n",
       "yahoo.com              0.0\n",
       "ymail.com              0.0\n",
       "412739                 0.0\n",
       "BEM6008                0.0\n",
       "BEM6728                0.0\n",
       "BEM6729                0.0\n",
       "sbcglobal.net          0.0\n",
       "BEM6737                0.0\n",
       "BEM6739                0.0\n",
       "BES1005                0.0\n",
       "BES3003                0.0\n",
       "BES5001                0.0\n",
       "ROUTEINS18             0.0\n",
       "ROUTEINS19             0.0\n",
       "ROUTEINS22             0.0\n",
       "Friday                 0.0\n",
       "Saturday               0.0\n",
       "BEM6738                0.0\n",
       "rocketmail.com         0.0\n",
       "580111                 0.0\n",
       "optonline.net          0.0\n",
       "earthlink.net          0.0\n",
       "charter.net            0.0\n",
       "bellsouth.net          0.0\n",
       "att.net                0.0\n",
       "outlook.com            0.0\n",
       "aim.com                0.0\n",
       "hold                   0.0\n",
       "aol.com                0.0\n",
       "icloud.com             0.0\n",
       "live.com               0.0\n",
       "mac.com                0.0\n",
       "me.com                 0.0\n",
       "msn.com                0.0\n",
       "comcast.net            0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the LEAST important features and eliminate those features from the X data set; then run the models again\n",
    "m4_unimportant = coff_m4.sort_values('Importance', ascending=True).head(39)\n",
    "m4_unimportant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these features have literally no importance on this Gradient Boosting Regressor. We will use these to drop the features so that we can build a model that works with the important features only and doesn't waste time on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.044418e+10</td>\n",
       "      <td>1.010976e+25</td>\n",
       "      <td>3.179585e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "0      Linear Regression  5.044418e+10  1.010976e+25  3.179585e+12\n",
       "1        Random Forest 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "3       Gradient Boost 1  1.847487e-01  6.807649e-02  2.609147e-01"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append({'Model':'Gradient Boost 1', 'MAE':m4_MAE, 'MSE':m4_MSE, 'RMSE':m4_RMSE}, ignore_index=True)\n",
    "perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Remove unimportant features\n",
    "The results from the first round of modeling were good, but there was a lot of unimportant features that were still considered by the models. Let's eliminate those features and see if we the models perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>custom</th>\n",
       "      <th>gmail.com</th>\n",
       "      <th>hotmail.com</th>\n",
       "      <th>1356615</th>\n",
       "      <th>294517</th>\n",
       "      <th>...</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39766</th>\n",
       "      <td>27.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.446848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>59.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777934</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>54.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.740126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>90.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.957512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39730 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_total  Marketing_first  first_items  Vendor  first_tot_lg  \\\n",
       "1           145.58                1            2     1.0      2.163102   \n",
       "2           137.55                0            5     1.0      2.138461   \n",
       "3            22.98                1            2     1.0      1.361350   \n",
       "4            28.00                0            1     0.0      1.447158   \n",
       "5            12.00                1            1     0.0      1.079181   \n",
       "...            ...              ...          ...     ...           ...   \n",
       "39766        27.98                0            2     1.0      1.446848   \n",
       "39767        59.97                0            2     1.0      1.777934   \n",
       "39768        54.97                1            2     1.0      1.740126   \n",
       "39769        90.68                0            3     1.0      1.957512   \n",
       "39770        25.00                0            1     0.0      1.397940   \n",
       "\n",
       "       custom  gmail.com  hotmail.com  1356615  294517  ...  December  \\\n",
       "1           1          0            0        0       0  ...         0   \n",
       "2           1          0            0        0       0  ...         0   \n",
       "3           1          0            0        0       0  ...         0   \n",
       "4           1          0            0        0       0  ...         0   \n",
       "5           1          0            0        0       0  ...         0   \n",
       "...       ...        ...          ...      ...     ...  ...       ...   \n",
       "39766       0          1            0        0       0  ...         0   \n",
       "39767       0          1            0        0       0  ...         0   \n",
       "39768       0          1            0        0       0  ...         0   \n",
       "39769       0          1            0        0       0  ...         0   \n",
       "39770       0          1            0        0       0  ...         0   \n",
       "\n",
       "       February  January  July  June  March  May  November  October  September  \n",
       "1             0        0     0     0      0    0         1        0          0  \n",
       "2             0        0     0     0      0    0         1        0          0  \n",
       "3             0        0     0     0      0    0         1        0          0  \n",
       "4             0        0     0     0      0    0         0        0          0  \n",
       "5             0        0     0     0      0    0         0        0          0  \n",
       "...         ...      ...   ...   ...    ...  ...       ...      ...        ...  \n",
       "39766         0        0     0     0      0    0         0        0          1  \n",
       "39767         0        0     0     0      0    0         0        0          1  \n",
       "39768         0        0     0     0      0    0         0        0          1  \n",
       "39769         0        0     0     0      0    0         0        0          1  \n",
       "39770         0        0     0     0      0    0         0        0          1  \n",
       "\n",
       "[39730 rows x 40 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the unimportant features\n",
    "unimport = list(set(m4_unimportant.index.tolist()) | set(m2_unimportant.index.tolist()))\n",
    "# remove unimportant features from Gradient Boosting\n",
    "X1 = X.drop(unimport, axis=1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That eliminated a lot of features and took us down to just 40 features! Excellent! <br>\n",
    "<br>\n",
    "Let's model with those features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8158008483225205, 1.8162965793223824)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's scale the X values\n",
    "scaler1 = preprocessing.StandardScaler().fit(X1)\n",
    "X1_scaled=scaler1.transform(X1)\n",
    "\n",
    "# split the X and y values again\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1_scaled, y, test_size=0.20, random_state=1)\n",
    "# check the mean values of the y to make sure this is a good split\n",
    "y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Linear regression on reduced feature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try standard linear regression on the data set with less features\n",
    "lm5 = linear_model.LinearRegression()\n",
    "model5 = lm5.fit(X1_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted results from the first model on the X_test values\n",
    "y5_pred = model5.predict(X1_test)\n",
    "# Mean Absolute Error\n",
    "m5_MAE = mean_absolute_error(y_test, y5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "m5_MSE = mean_squared_error(y_test, y5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Squared Error\n",
    "m5_RMSE = m5_MSE**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.044418e+10</td>\n",
       "      <td>1.010976e+25</td>\n",
       "      <td>3.179585e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.858921e-01</td>\n",
       "      <td>6.770492e-02</td>\n",
       "      <td>2.602017e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "0      Linear Regression  5.044418e+10  1.010976e+25  3.179585e+12\n",
       "1        Random Forest 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "3       Gradient Boost 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "4    Linear Regression 2  1.858921e-01  6.770492e-02  2.602017e-01"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append({'Model':'Linear Regression 2', 'MAE':m5_MAE, 'MSE':m5_MSE, 'RMSE':m5_RMSE}, ignore_index=True)\n",
    "perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated version of linear regression actually performed better than the first attempt at Random Forest Regression or Gradient Boost Regression. That's great to see that eliminating those features lead to such improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest Regression with reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a minimum sample of 40 or 1/1000th of the total number of customers\n",
    "regr1 = RandomForestRegressor(min_samples_leaf=40, random_state=33)\n",
    "model1_rf = regr.fit(X1_train,y_train)\n",
    "y_pred1_rf = regr.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.044418e+10</td>\n",
       "      <td>1.010976e+25</td>\n",
       "      <td>3.179585e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.858921e-01</td>\n",
       "      <td>6.770492e-02</td>\n",
       "      <td>2.602017e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.846553e-01</td>\n",
       "      <td>6.810615e-02</td>\n",
       "      <td>2.609715e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "0      Linear Regression  5.044418e+10  1.010976e+25  3.179585e+12\n",
       "1        Random Forest 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "3       Gradient Boost 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "4    Linear Regression 2  1.858921e-01  6.770492e-02  2.602017e-01\n",
       "5        Random Forest 2  1.846553e-01  6.810615e-02  2.609715e-01"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "m6_MAE = mean_absolute_error(y_test, y_pred1_rf)\n",
    "# Mean Squared Error\n",
    "m6_MSE = mean_squared_error(y_test, y_pred1_rf)\n",
    "# root mean squared error\n",
    "m6_RMSE = m6_MSE**0.5\n",
    "# add to performance DF\n",
    "perform = perform.append({'Model':'Random Forest 2', 'MAE':m6_MAE, 'MSE':m6_MSE, 'RMSE':m6_RMSE}, ignore_index=True)\n",
    "perform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these values look good, but similar to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gradient Boost with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.044418e+10</td>\n",
       "      <td>1.010976e+25</td>\n",
       "      <td>3.179585e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847487e-01</td>\n",
       "      <td>6.807649e-02</td>\n",
       "      <td>2.609147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.858921e-01</td>\n",
       "      <td>6.770492e-02</td>\n",
       "      <td>2.602017e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.846553e-01</td>\n",
       "      <td>6.810615e-02</td>\n",
       "      <td>2.609715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.846553e-01</td>\n",
       "      <td>6.810615e-02</td>\n",
       "      <td>2.609715e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "0      Linear Regression  5.044418e+10  1.010976e+25  3.179585e+12\n",
       "1        Random Forest 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "3       Gradient Boost 1  1.847487e-01  6.807649e-02  2.609147e-01\n",
       "4    Linear Regression 2  1.858921e-01  6.770492e-02  2.602017e-01\n",
       "5        Random Forest 2  1.846553e-01  6.810615e-02  2.609715e-01\n",
       "6       Gradient Boost 2  1.846553e-01  6.810615e-02  2.609715e-01"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor\n",
    "reg1_gb = GradientBoostingRegressor(min_samples_leaf=40, random_state=0)\n",
    "model1_gb = reg_gb.fit(X1_train,y_train)\n",
    "# use regressor to predict on test data\n",
    "y_pred1_gb = regr.predict(X1_test)\n",
    "# compare test data for a score - Mean Absolute Error\n",
    "m7_MAE = mean_absolute_error(y_test, y_pred1_gb)\n",
    "# Mean Squared Error\n",
    "m7_MSE = mean_squared_error(y_test, y_pred1_gb)\n",
    "# root mean squared error\n",
    "m7_RMSE = m7_MSE**0.5\n",
    "perform = perform.append({'Model':'Gradient Boost 2', 'MAE':m7_MAE, 'MSE':m7_MSE, 'RMSE':m7_RMSE}, ignore_index=True)\n",
    "perform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look like great models (except for the first Linear Regression). Let's see if tuning the hyperparameters can make them better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took a guess at a good hyperparameter of 40 for the minimum number of leaves per node. That looked like a good start relative to the Linear Regression results. Instead, we should also consider multiple values for the hyperparameter for both the Gradient Boost and Random Forest Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>926</td>\n",
       "      <td>0.192646</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.265518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>789</td>\n",
       "      <td>0.192539</td>\n",
       "      <td>0.070341</td>\n",
       "      <td>0.265218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>584</td>\n",
       "      <td>0.191470</td>\n",
       "      <td>0.069895</td>\n",
       "      <td>0.264377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>333</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>0.069295</td>\n",
       "      <td>0.263239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>72</td>\n",
       "      <td>0.185817</td>\n",
       "      <td>0.068375</td>\n",
       "      <td>0.261486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>813</td>\n",
       "      <td>0.192565</td>\n",
       "      <td>0.070371</td>\n",
       "      <td>0.265276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>131</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>0.068551</td>\n",
       "      <td>0.261822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183426</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>56</td>\n",
       "      <td>0.185422</td>\n",
       "      <td>0.068304</td>\n",
       "      <td>0.261350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>434</td>\n",
       "      <td>0.190761</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.263897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.260771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>856</td>\n",
       "      <td>0.192544</td>\n",
       "      <td>0.070362</td>\n",
       "      <td>0.265259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>299</td>\n",
       "      <td>0.189241</td>\n",
       "      <td>0.069145</td>\n",
       "      <td>0.262955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>163</td>\n",
       "      <td>0.187508</td>\n",
       "      <td>0.068684</td>\n",
       "      <td>0.262077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>607</td>\n",
       "      <td>0.191560</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>0.264438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63</td>\n",
       "      <td>0.185611</td>\n",
       "      <td>0.068341</td>\n",
       "      <td>0.261421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>371</td>\n",
       "      <td>0.189939</td>\n",
       "      <td>0.069390</td>\n",
       "      <td>0.263419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>421</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>0.069611</td>\n",
       "      <td>0.263839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>592</td>\n",
       "      <td>0.191487</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.264391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Node_size       MAE       MSE      RMSE\n",
       "0   Random Forest       926  0.192646  0.070500  0.265518\n",
       "1   Random Forest       789  0.192539  0.070341  0.265218\n",
       "2   Random Forest       584  0.191470  0.069895  0.264377\n",
       "3   Random Forest       333  0.189634  0.069295  0.263239\n",
       "4   Random Forest        72  0.185817  0.068375  0.261486\n",
       "5   Random Forest       813  0.192565  0.070371  0.265276\n",
       "6   Random Forest       131  0.187026  0.068551  0.261822\n",
       "7   Random Forest        18  0.183426  0.068089  0.260938\n",
       "8   Random Forest        56  0.185422  0.068304  0.261350\n",
       "9   Random Forest       434  0.190761  0.069641  0.263897\n",
       "10  Random Forest        28  0.183991  0.068002  0.260771\n",
       "11  Random Forest       856  0.192544  0.070362  0.265259\n",
       "12  Random Forest       299  0.189241  0.069145  0.262955\n",
       "13  Random Forest        27  0.183901  0.067997  0.260763\n",
       "14  Random Forest       163  0.187508  0.068684  0.262077\n",
       "15  Random Forest       607  0.191560  0.069927  0.264438\n",
       "16  Random Forest        63  0.185611  0.068341  0.261421\n",
       "17  Random Forest       371  0.189939  0.069390  0.263419\n",
       "18  Random Forest       421  0.190682  0.069611  0.263839\n",
       "19  Random Forest       592  0.191487  0.069903  0.264391"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "node_size = random.sample(range(10,1000), 20)\n",
    "\n",
    "perform_h = pd.DataFrame(columns=['Model', 'Node_size', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# loops through the number of leaves\n",
    "for n in node_size:\n",
    "    reg_h = RandomForestRegressor(min_samples_leaf=n, random_state=33)\n",
    "    model_rf_h = reg_h.fit(X1_train,y_train)\n",
    "    y_pred1_rf_h = reg_h.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred1_rf_h)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred1_rf_h)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_h = perform_h.append({'Model':'Random Forest', 'Node_size':n, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These all look extremely similiar, let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_h['Node_size'], perform_h['RMSE'])\n",
    "plt.xlabel('Minimum Node size')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks like it trends downwards with smaller minimum node size, as it's allowed to fit the model more closely to the data. Let's try a different range of values to select from and iterate one more time on that hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>926</td>\n",
       "      <td>0.192646</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.265518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>789</td>\n",
       "      <td>0.192539</td>\n",
       "      <td>0.070341</td>\n",
       "      <td>0.265218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>584</td>\n",
       "      <td>0.191470</td>\n",
       "      <td>0.069895</td>\n",
       "      <td>0.264377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>333</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>0.069295</td>\n",
       "      <td>0.263239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>72</td>\n",
       "      <td>0.185817</td>\n",
       "      <td>0.068375</td>\n",
       "      <td>0.261486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>813</td>\n",
       "      <td>0.192565</td>\n",
       "      <td>0.070371</td>\n",
       "      <td>0.265276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>131</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>0.068551</td>\n",
       "      <td>0.261822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183426</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>56</td>\n",
       "      <td>0.185422</td>\n",
       "      <td>0.068304</td>\n",
       "      <td>0.261350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>434</td>\n",
       "      <td>0.190761</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.263897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.260771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>856</td>\n",
       "      <td>0.192544</td>\n",
       "      <td>0.070362</td>\n",
       "      <td>0.265259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>299</td>\n",
       "      <td>0.189241</td>\n",
       "      <td>0.069145</td>\n",
       "      <td>0.262955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>163</td>\n",
       "      <td>0.187508</td>\n",
       "      <td>0.068684</td>\n",
       "      <td>0.262077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>607</td>\n",
       "      <td>0.191560</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>0.264438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>63</td>\n",
       "      <td>0.185611</td>\n",
       "      <td>0.068341</td>\n",
       "      <td>0.261421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>371</td>\n",
       "      <td>0.189939</td>\n",
       "      <td>0.069390</td>\n",
       "      <td>0.263419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>421</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>0.069611</td>\n",
       "      <td>0.263839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>592</td>\n",
       "      <td>0.191487</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.264391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>19</td>\n",
       "      <td>0.183435</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.260853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>13</td>\n",
       "      <td>0.183026</td>\n",
       "      <td>0.068248</td>\n",
       "      <td>0.261242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>21</td>\n",
       "      <td>0.183620</td>\n",
       "      <td>0.068030</td>\n",
       "      <td>0.260827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24</td>\n",
       "      <td>0.183764</td>\n",
       "      <td>0.068029</td>\n",
       "      <td>0.260824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>20</td>\n",
       "      <td>0.183566</td>\n",
       "      <td>0.068055</td>\n",
       "      <td>0.260873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>17</td>\n",
       "      <td>0.183368</td>\n",
       "      <td>0.068107</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.260771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.183033</td>\n",
       "      <td>0.069803</td>\n",
       "      <td>0.264202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>23</td>\n",
       "      <td>0.183687</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.260808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8</td>\n",
       "      <td>0.182656</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.262276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>25</td>\n",
       "      <td>0.183818</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>0.260811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>26</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>0.067990</td>\n",
       "      <td>0.260749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>12</td>\n",
       "      <td>0.182969</td>\n",
       "      <td>0.068289</td>\n",
       "      <td>0.261322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182729</td>\n",
       "      <td>0.068442</td>\n",
       "      <td>0.261614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>15</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.261128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>11</td>\n",
       "      <td>0.182823</td>\n",
       "      <td>0.068342</td>\n",
       "      <td>0.261423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>7</td>\n",
       "      <td>0.182801</td>\n",
       "      <td>0.069035</td>\n",
       "      <td>0.262746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>22</td>\n",
       "      <td>0.183680</td>\n",
       "      <td>0.068042</td>\n",
       "      <td>0.260848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>6</td>\n",
       "      <td>0.182845</td>\n",
       "      <td>0.069365</td>\n",
       "      <td>0.263372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Node_size       MAE       MSE      RMSE\n",
       "0   Random Forest       926  0.192646  0.070500  0.265518\n",
       "1   Random Forest       789  0.192539  0.070341  0.265218\n",
       "2   Random Forest       584  0.191470  0.069895  0.264377\n",
       "3   Random Forest       333  0.189634  0.069295  0.263239\n",
       "4   Random Forest        72  0.185817  0.068375  0.261486\n",
       "5   Random Forest       813  0.192565  0.070371  0.265276\n",
       "6   Random Forest       131  0.187026  0.068551  0.261822\n",
       "7   Random Forest        18  0.183426  0.068089  0.260938\n",
       "8   Random Forest        56  0.185422  0.068304  0.261350\n",
       "9   Random Forest       434  0.190761  0.069641  0.263897\n",
       "10  Random Forest        28  0.183991  0.068002  0.260771\n",
       "11  Random Forest       856  0.192544  0.070362  0.265259\n",
       "12  Random Forest       299  0.189241  0.069145  0.262955\n",
       "13  Random Forest        27  0.183901  0.067997  0.260763\n",
       "14  Random Forest       163  0.187508  0.068684  0.262077\n",
       "15  Random Forest       607  0.191560  0.069927  0.264438\n",
       "16  Random Forest        63  0.185611  0.068341  0.261421\n",
       "17  Random Forest       371  0.189939  0.069390  0.263419\n",
       "18  Random Forest       421  0.190682  0.069611  0.263839\n",
       "19  Random Forest       592  0.191487  0.069903  0.264391\n",
       "20  Random Forest        19  0.183435  0.068044  0.260853\n",
       "21  Random Forest        13  0.183026  0.068248  0.261242\n",
       "22  Random Forest        21  0.183620  0.068030  0.260827\n",
       "23  Random Forest        24  0.183764  0.068029  0.260824\n",
       "24  Random Forest        20  0.183566  0.068055  0.260873\n",
       "25  Random Forest        17  0.183368  0.068107  0.260972\n",
       "26  Random Forest        28  0.183991  0.068002  0.260771\n",
       "27  Random Forest         5  0.183033  0.069803  0.264202\n",
       "28  Random Forest        23  0.183687  0.068021  0.260808\n",
       "29  Random Forest         8  0.182656  0.068789  0.262276\n",
       "30  Random Forest        25  0.183818  0.068022  0.260811\n",
       "31  Random Forest        26  0.183825  0.067990  0.260749\n",
       "32  Random Forest        12  0.182969  0.068289  0.261322\n",
       "33  Random Forest        27  0.183901  0.067997  0.260763\n",
       "34  Random Forest        10  0.182729  0.068442  0.261614\n",
       "35  Random Forest        15  0.183200  0.068188  0.261128\n",
       "36  Random Forest        11  0.182823  0.068342  0.261423\n",
       "37  Random Forest         7  0.182801  0.069035  0.262746\n",
       "38  Random Forest        22  0.183680  0.068042  0.260848\n",
       "39  Random Forest         6  0.182845  0.069365  0.263372"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much smaller minimum node size \n",
    "node_size = random.sample(range(5,30), 20)\n",
    "\n",
    "# we'll add on to the existing DF so we get a better look at the full curve\n",
    "\n",
    "# loops through the number of leaves\n",
    "for n in node_size:\n",
    "    reg_h = RandomForestRegressor(min_samples_leaf=n, random_state=33)\n",
    "    model_rf_h = reg_h.fit(X1_train,y_train)\n",
    "    y_pred1_rf_h = reg_h.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred1_rf_h)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred1_rf_h)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_h = perform_h.append({'Model':'Random Forest', 'Node_size':n, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_h['Node_size'], perform_h['RMSE'])\n",
    "plt.xlabel('Minimum Node size')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the dip that I wanted to see to consider a balance between under and over-fitting to the data. Let's find the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>26</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>0.067990</td>\n",
       "      <td>0.260749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183901</td>\n",
       "      <td>0.067997</td>\n",
       "      <td>0.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.260771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>28</td>\n",
       "      <td>0.183991</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>0.260771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>23</td>\n",
       "      <td>0.183687</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.260808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>25</td>\n",
       "      <td>0.183818</td>\n",
       "      <td>0.068022</td>\n",
       "      <td>0.260811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>24</td>\n",
       "      <td>0.183764</td>\n",
       "      <td>0.068029</td>\n",
       "      <td>0.260824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>21</td>\n",
       "      <td>0.183620</td>\n",
       "      <td>0.068030</td>\n",
       "      <td>0.260827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>22</td>\n",
       "      <td>0.183680</td>\n",
       "      <td>0.068042</td>\n",
       "      <td>0.260848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Node_size       MAE       MSE      RMSE\n",
       "31  Random Forest        26  0.183825  0.067990  0.260749\n",
       "33  Random Forest        27  0.183901  0.067997  0.260763\n",
       "13  Random Forest        27  0.183901  0.067997  0.260763\n",
       "26  Random Forest        28  0.183991  0.068002  0.260771\n",
       "10  Random Forest        28  0.183991  0.068002  0.260771\n",
       "28  Random Forest        23  0.183687  0.068021  0.260808\n",
       "30  Random Forest        25  0.183818  0.068022  0.260811\n",
       "23  Random Forest        24  0.183764  0.068029  0.260824\n",
       "22  Random Forest        21  0.183620  0.068030  0.260827\n",
       "38  Random Forest        22  0.183680  0.068042  0.260848"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_h.sort_values('RMSE', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 26 is the best minimum node size for Random Forest Regression with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Gradient Boosting with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same hyperparameter tuning, but with Gradient Boosting. We may consider a different parameter to change for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.308899</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.849102</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.040345</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.986303</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.201691</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.050485</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.420240</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.018922</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.366527</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.260972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Learning_rate       MAE       MSE      RMSE\n",
       "0   Gradient Boost       0.308899  0.184655  0.068106  0.260972\n",
       "17  Gradient Boost       0.039540  0.184655  0.068106  0.260972\n",
       "16  Gradient Boost       0.849102  0.184655  0.068106  0.260972\n",
       "15  Gradient Boost       0.040345  0.184655  0.068106  0.260972\n",
       "14  Gradient Boost       0.986303  0.184655  0.068106  0.260972\n",
       "13  Gradient Boost       0.201691  0.184655  0.068106  0.260972\n",
       "12  Gradient Boost       0.050485  0.184655  0.068106  0.260972\n",
       "11  Gradient Boost       0.420240  0.184655  0.068106  0.260972\n",
       "10  Gradient Boost       0.018922  0.184655  0.068106  0.260972\n",
       "9   Gradient Boost       0.366527  0.184655  0.068106  0.260972"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much smaller minimum node size \n",
    "learn_rt = [random.random() for x in range(20)]\n",
    "\n",
    "# we'll add on to the existing DF so we get a better look at the full curve\n",
    "perform_gb = pd.DataFrame(columns=['Model', 'Learning_rate', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# loops through the number of leaves\n",
    "for r in learn_rt:\n",
    "    reg_gb = GradientBoostingRegressor(learning_rate=r, random_state=0)\n",
    "    model_gb = reg_gb.fit(X1_train,y_train)\n",
    "    # use regressor to predict on test data\n",
    "    y_pred_gb = regr.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred_gb)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred_gb)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_gb = perform_gb.append({'Model':'Gradient Boost', 'Learning_rate':r, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_gb.sort_values('RMSE', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_gb['Learning_rate'], perform_gb['RMSE'])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. More Extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we did some hyperparameter tuning, but this was just using a random search of one parameter. It may not even be the best parameter to tune. Instead, we will focus on doing a more extensive search in this section. We will form a grid for both Random Forest and Gradient Boosting. We will then using random search to pick out some points on that grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Random Forest Regression with more extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [10, 26, 40], 'min_samples_leaf': [10, 26, 40], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "### create the grid of hyperparameters to use\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10, 26, 40]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [10, 26, 40]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 105.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 233.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [10, 26, 40],\n",
       "                                        'min_samples_split': [10, 26, 40],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=33, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run the random search of that grid that we just created\n",
    "\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=33, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X1_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=10,\n",
       "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1200, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18455484506737924, 0.06763656426139242, 0.26097154337047773)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how these parameters performed\n",
    "# rf_h = RandomForestRegressor(rf_random.best_params_)\n",
    "model_rf_h = rf_random.best_estimator_\n",
    "y_pred_h_rf = model_rf_h.predict(X1_test)\n",
    "\n",
    "# let's see the error\n",
    "# Mean Absolute Error\n",
    "rf_h_MAE = mean_absolute_error(y_test, y_pred_h_rf)\n",
    "# Mean Squared Error\n",
    "rf_h_MSE = mean_squared_error(y_test, y_pred_h_rf)\n",
    "# root mean squared error\n",
    "rf_h_RMSE = m6_MSE**0.5\n",
    "\n",
    "# display\n",
    "rf_h_MAE, rf_h_MSE, rf_h_RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is barely any different the the resutls we got from the values we had previously, but I will still use those values in future Random Forest Models with this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Grandient Boost Regression with more extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
