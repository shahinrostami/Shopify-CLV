{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of this notebook:\n",
    "### 1. Preprocesses the data to prepare for modeling\n",
    "### 2. Modeling using a number of different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Preprocessing\n",
    "We get the data ready to model by dropping some features, creating dummy variables for catagorical features, and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "os.chdir(\"C:\\Springboard\\Github\\Capstone2_cust\\Intermediate_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>first_order</th>\n",
       "      <th>server</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Source</th>\n",
       "      <th>Area_Code</th>\n",
       "      <th>Ship_Zip</th>\n",
       "      <th>lead_sku</th>\n",
       "      <th>weekday</th>\n",
       "      <th>mon</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>first_it_lg</th>\n",
       "      <th>boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-26 21:44:16+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>404</td>\n",
       "      <td>30087</td>\n",
       "      <td>other</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-11-26 20:52:08+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>845</td>\n",
       "      <td>12545</td>\n",
       "      <td>other</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-26 18:12:04+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>web</td>\n",
       "      <td>262</td>\n",
       "      <td>53402</td>\n",
       "      <td>ROUTEINS10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>November</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-07 18:14:49+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>617</td>\n",
       "      <td>01983</td>\n",
       "      <td>BEM1003</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-07 18:05:28+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>740</td>\n",
       "      <td>43143</td>\n",
       "      <td>other</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-07 03:45:52+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>701</td>\n",
       "      <td>58801</td>\n",
       "      <td>BES1006</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.623249</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-06 22:00:54+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>754</td>\n",
       "      <td>33026</td>\n",
       "      <td>BEM6001</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.434569</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-06 20:22:25+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>unknown</td>\n",
       "      <td>01880</td>\n",
       "      <td>BES5001</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.342423</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-06 19:59:05+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>617</td>\n",
       "      <td>01880</td>\n",
       "      <td>BEM1007</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-06 19:14:49+00:00</td>\n",
       "      <td>custom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>web</td>\n",
       "      <td>626</td>\n",
       "      <td>92887</td>\n",
       "      <td>BEM1007</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>1.563955</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_total  Marketing_first  first_items               first_order  \\\n",
       "1        145.58                1            2 2019-11-26 21:44:16+00:00   \n",
       "2        137.55                0            5 2019-11-26 20:52:08+00:00   \n",
       "3         22.98                1            2 2019-11-26 18:12:04+00:00   \n",
       "4         28.00                0            1 2019-08-07 18:14:49+00:00   \n",
       "5         12.00                1            1 2019-08-07 18:05:28+00:00   \n",
       "6         42.00                0            2 2019-08-07 03:45:52+00:00   \n",
       "7         27.20                1            1 2019-08-06 22:00:54+00:00   \n",
       "8         22.00                1            2 2019-08-06 20:22:25+00:00   \n",
       "9        100.00                1            5 2019-08-06 19:59:05+00:00   \n",
       "10        36.64                1            2 2019-08-06 19:14:49+00:00   \n",
       "\n",
       "    server  Vendor Source Area_Code Ship_Zip    lead_sku    weekday       mon  \\\n",
       "1   custom     1.0    web       404    30087       other    Tuesday  November   \n",
       "2   custom     1.0    web       845    12545       other    Tuesday  November   \n",
       "3   custom     1.0    web       262    53402  ROUTEINS10    Tuesday  November   \n",
       "4   custom     0.0    web       617    01983     BEM1003  Wednesday    August   \n",
       "5   custom     0.0    web       740    43143       other  Wednesday    August   \n",
       "6   custom     0.0    web       701    58801     BES1006  Wednesday    August   \n",
       "7   custom     0.0    web       754    33026     BEM6001    Tuesday    August   \n",
       "8   custom     0.0    web   unknown    01880     BES5001    Tuesday    August   \n",
       "9   custom     0.0    web       617    01880     BEM1007    Tuesday    August   \n",
       "10  custom     0.0    web       626    92887     BEM1007    Tuesday    August   \n",
       "\n",
       "    first_tot_lg  first_it_lg  boost  \n",
       "1       2.163102      0.30103      1  \n",
       "2       2.138461      0.69897      1  \n",
       "3       1.361350      0.30103      1  \n",
       "4       1.447158      0.00000      1  \n",
       "5       1.079181      0.00000      1  \n",
       "6       1.623249      0.30103      1  \n",
       "7       1.434569      0.00000      1  \n",
       "8       1.342423      0.30103      1  \n",
       "9       2.000000      0.69897      1  \n",
       "10      1.563955      0.30103      1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load picked version of X\n",
    "X = pickle.load(open(\"X2.pkl\", \"rb\"))\n",
    "# look at the first 10 rows of this file\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. Let's review what each column means: <br>\n",
    "- first_total: total $ spend on first order <br>\n",
    "- Marketing_first: whether they accept marketing on the first order <br>\n",
    "- first_items: number of items on first order <br>\n",
    "- first_order: date-time of first order <br>\n",
    "- server: domain name of the customer email server <br>\n",
    "- vendor: 0 = first order from company; 1 = first order from outside source <br>\n",
    "- Source: web or iphone\n",
    "- Area_Code: area code of order placed\n",
    "- Ship_Zip: zip code of shipping address\n",
    "- lead_sku: name of SKU that was lead item on purchase\n",
    "- weekday: day of week first order was placed\n",
    "- mon: month that first order was placed\n",
    "- first_tot_lg: log of first order total\n",
    "- first_it_lg: log of number of items in first order <br>\n",
    "<br>\n",
    "The values for some of these catagorical features need to be converted to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "web        33949\n",
       "1356615     5423\n",
       "294517       273\n",
       "457101        67\n",
       "580111        16\n",
       "412739         2\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop first order item log\n",
    "X.drop('first_it_lg', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39730 entries, 1 to 39770\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   first_total      39730 non-null  float64            \n",
      " 1   Marketing_first  39730 non-null  int64              \n",
      " 2   first_items      39730 non-null  int64              \n",
      " 3   first_order      39730 non-null  datetime64[ns, UTC]\n",
      " 4   server           39730 non-null  object             \n",
      " 5   Vendor           39730 non-null  float64            \n",
      " 6   Source           39730 non-null  object             \n",
      " 7   Area_Code        39730 non-null  object             \n",
      " 8   Ship_Zip         39730 non-null  object             \n",
      " 9   lead_sku         39730 non-null  object             \n",
      " 10  weekday          39730 non-null  object             \n",
      " 11  mon              39730 non-null  object             \n",
      " 12  first_tot_lg     39730 non-null  float64            \n",
      " 13  boost            39730 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(3), int64(3), object(7)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traditional regression can't handle date-time, so we'll drop that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date-time\n",
    "X.drop('first_order', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features that need dummy variables:\n",
    "- server\n",
    "- source\n",
    "- Area_Code\n",
    "- Ship_Zip\n",
    "- lead_sku\n",
    "- weekday\n",
    "- mon <br>\n",
    "<br>\n",
    "Let's look at the size of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['server'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Source'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Area_Code'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is too man catagorical variables for this feature. I wonder if there are high concentrations of purchases in some zip codes that we could account for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    21387\n",
       "949          273\n",
       "714          204\n",
       "720          161\n",
       "760          155\n",
       "310          148\n",
       "214          144\n",
       "512          144\n",
       "817          139\n",
       "801          135\n",
       "757          132\n",
       "917          131\n",
       "208          131\n",
       "909          130\n",
       "503          130\n",
       "916          129\n",
       "704          129\n",
       "360          128\n",
       "619          127\n",
       "480          121\n",
       "Name: Area_Code, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Area_Code'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 40k customers, so the largest area code makes up 0.68% of total orders. I think this feature is too small and would add unnecessary dimensions. We will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('Area_Code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15930"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Ship_Zip'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is way too many features. Unless they are very concentrated in a few zip codes, we'll drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92688      48\n",
       "92692      48\n",
       "unknown    48\n",
       "92691      46\n",
       "28532      41\n",
       "92694      40\n",
       "92630      39\n",
       "92627      38\n",
       "92656      31\n",
       "92679      29\n",
       "92677      27\n",
       "92675      25\n",
       "92672      24\n",
       "92626      23\n",
       "92592      22\n",
       "92629      22\n",
       "80013      22\n",
       "92660      21\n",
       "79936      20\n",
       "93551      20\n",
       "Name: Ship_Zip, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Ship_Zip'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest zip code is still WAY too small. We'll drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop that feature\n",
    "X.drop('Ship_Zip', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['lead_sku'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how many variables for days of the week and month there are. This means we should see: <br>\n",
    "- server: 26\n",
    "- source: 6\n",
    "- lead_sku: 26\n",
    "- weekday: 7\n",
    "- mon: 12 <br>\n",
    "- total: 77 more freatures <br>\n",
    "<br>\n",
    "That seems reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy for server ##\n",
    "dfs = X['server']\n",
    "dummy_server = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('server', axis=1), dummy_server], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for Source\n",
    "dfs = X['Source']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('Source', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for lead_sku\n",
    "dfs = X['lead_sku']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('lead_sku', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for weekday\n",
    "dfs = X['weekday']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('weekday', axis=1), dummy_source], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>boost</th>\n",
       "      <th>aim.com</th>\n",
       "      <th>aol.com</th>\n",
       "      <th>att.net</th>\n",
       "      <th>bellsouth.net</th>\n",
       "      <th>...</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39766</th>\n",
       "      <td>27.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.446848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>59.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>54.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.740126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>90.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.957512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39730 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_total  Marketing_first  first_items  Vendor  first_tot_lg  boost  \\\n",
       "1           145.58                1            2     1.0      2.163102      1   \n",
       "2           137.55                0            5     1.0      2.138461      1   \n",
       "3            22.98                1            2     1.0      1.361350      1   \n",
       "4            28.00                0            1     0.0      1.447158      1   \n",
       "5            12.00                1            1     0.0      1.079181      1   \n",
       "...            ...              ...          ...     ...           ...    ...   \n",
       "39766        27.98                0            2     1.0      1.446848      1   \n",
       "39767        59.97                0            2     1.0      1.777934      1   \n",
       "39768        54.97                1            2     1.0      1.740126      1   \n",
       "39769        90.68                0            3     1.0      1.957512      1   \n",
       "39770        25.00                0            1     0.0      1.397940      1   \n",
       "\n",
       "       aim.com  aol.com  att.net  bellsouth.net  ...  December  February  \\\n",
       "1            0        0        0              0  ...         0         0   \n",
       "2            0        0        0              0  ...         0         0   \n",
       "3            0        0        0              0  ...         0         0   \n",
       "4            0        0        0              0  ...         0         0   \n",
       "5            0        0        0              0  ...         0         0   \n",
       "...        ...      ...      ...            ...  ...       ...       ...   \n",
       "39766        0        0        0              0  ...         0         0   \n",
       "39767        0        0        0              0  ...         0         0   \n",
       "39768        0        0        0              0  ...         0         0   \n",
       "39769        0        0        0              0  ...         0         0   \n",
       "39770        0        0        0              0  ...         0         0   \n",
       "\n",
       "       January  July  June  March  May  November  October  September  \n",
       "1            0     0     0      0    0         1        0          0  \n",
       "2            0     0     0      0    0         1        0          0  \n",
       "3            0     0     0      0    0         1        0          0  \n",
       "4            0     0     0      0    0         0        0          0  \n",
       "5            0     0     0      0    0         0        0          0  \n",
       "...        ...   ...   ...    ...  ...       ...      ...        ...  \n",
       "39766        0     0     0      0    0         0        0          1  \n",
       "39767        0     0     0      0    0         0        0          1  \n",
       "39768        0     0     0      0    0         0        0          1  \n",
       "39769        0     0     0      0    0         0        0          1  \n",
       "39770        0     0     0      0    0         0        0          1  \n",
       "\n",
       "[39730 rows x 83 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy for weekday\n",
    "dfs = X['mon']\n",
    "dummy_source = pd.get_dummies(dfs)\n",
    "X = pd.concat([X.drop('mon', axis=1), dummy_source], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good. Let's load Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2.163102\n",
       "2     2.138461\n",
       "3     1.361350\n",
       "4     1.447158\n",
       "5     1.079181\n",
       "6     1.623249\n",
       "7     1.434569\n",
       "8     1.342423\n",
       "9     2.000000\n",
       "10    1.563955\n",
       "Name: life_lg, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load picked version of X\n",
    "y = pickle.load(open(\"Y2.pkl\", \"rb\"))\n",
    "# look at the first 10 rows of this file\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the X values\n",
    "# Here we use the StandardScaler() method of the preprocessing package, and then call the fit() method with parameter X \n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "# Declare a variable called X_scaled, and assign it the result of calling the transform() method with parameter X \n",
    "X_scaled=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the 1-dimensional flattened array of our response variable y by calling the ravel() function on y\n",
    "y = y.ravel()\n",
    "\n",
    "# let's do the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8158008483225205, 1.8162965793223824)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's quickly check that the Y means to make sure the data sets are similiar\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those look reasonably close. <br>\n",
    "<br>\n",
    "That is the end of preprocessing. Time to model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modeling\n",
    "We will try a few different models: <br>\n",
    "- Linear Regression\n",
    "- Random Forest Regressor\n",
    "- Dummy Model (assume every customer is average)\n",
    "- Gradient Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to track model performance\n",
    "perform = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first model from X-train\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10413803859.800573"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted results from the first model on the X_test values\n",
    "y_pred = model.predict(X_test)\n",
    "# Mean Absolute Error\n",
    "m1_MAE = mean_absolute_error(y_test, y_pred)\n",
    "m1_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3086116591378785e+23"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m1_MSE = mean_squared_error(y_test, y_pred)\n",
    "m1_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values seem extremely high. I want to look at some of the values in the model really quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2082760773.7394059\n"
     ]
    }
   ],
   "source": [
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems way off with linear regression. Let's see if Random Forest Regressor looks any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "m1_RMSE = m1_MSE**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Linear Regression 1', 'MAE':m1_MAE, 'MSE':m1_MSE, 'RMSE':m1_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a minimum sample of 40 or 1/1000th of the total number of customers\n",
    "regr = RandomForestRegressor(min_samples_leaf=40, random_state=33)\n",
    "model_rf = regr.fit(X_train,y_train)\n",
    "y_pred_rf = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.184755203593603"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "m2_MAE = mean_absolute_error(y_test, y_pred_rf)\n",
    "m2_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06807909868651355"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m2_MSE = mean_squared_error(y_test, y_pred_rf)\n",
    "m2_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26091971693705623"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m2_RMSE = m2_MSE**0.5\n",
    "m2_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is so much better! <br>\n",
    "Let's look at the importance of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_tot_lg</th>\n",
       "      <td>0.480089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_total</th>\n",
       "      <td>0.460997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November</th>\n",
       "      <td>0.011767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356615</th>\n",
       "      <td>0.007362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_items</th>\n",
       "      <td>0.003836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gmail.com</th>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December</th>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing_first</th>\n",
       "      <td>0.002906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>January</th>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>0.002086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February</th>\n",
       "      <td>0.001912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS10</th>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>April</th>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor</th>\n",
       "      <td>0.001357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yahoo.com</th>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web</th>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Importance\n",
       "first_tot_lg       0.480089\n",
       "first_total        0.460997\n",
       "November           0.011767\n",
       "1356615            0.007362\n",
       "first_items        0.003836\n",
       "gmail.com          0.003755\n",
       "December           0.002959\n",
       "Marketing_first    0.002906\n",
       "January            0.002185\n",
       "July               0.002086\n",
       "February           0.001912\n",
       "ROUTEINS10         0.001487\n",
       "April              0.001370\n",
       "Vendor             0.001357\n",
       "June               0.001306\n",
       "other              0.001299\n",
       "yahoo.com          0.001150\n",
       "May                0.000953\n",
       "Monday             0.000923\n",
       "web                0.000889"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coff_m2 = pd.DataFrame(model_rf.feature_importances_, X.columns, columns=['Importance'])\n",
    "coff_m2.sort_values('Importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are good see. <br>\n",
    "We may want to use these values to eliminate some variable from the regression model, but first let's compare the RMSE and AMSE to a dummy model that just assumes very customer is average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEM1007</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msn.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlook.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocketmail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbcglobal.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verizon.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1005</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457101</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580111</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM1009</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windstream.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optonline.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charter.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthlink.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cox.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES3003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES5001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellsouth.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importance\n",
       "BEM1007                0.0\n",
       "me.com                 0.0\n",
       "msn.com                0.0\n",
       "outlook.com            0.0\n",
       "rocketmail.com         0.0\n",
       "sbcglobal.net          0.0\n",
       "vendor                 0.0\n",
       "mac.com                0.0\n",
       "verizon.net            0.0\n",
       "BES1005                0.0\n",
       "ymail.com              0.0\n",
       "412739                 0.0\n",
       "457101                 0.0\n",
       "580111                 0.0\n",
       "BEM1009                0.0\n",
       "windstream.net         0.0\n",
       "live.com               0.0\n",
       "optonline.net          0.0\n",
       "charter.net            0.0\n",
       "hold                   0.0\n",
       "earthlink.net          0.0\n",
       "cox.net                0.0\n",
       "BES3003                0.0\n",
       "BES5001                0.0\n",
       "bellsouth.net          0.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the least important values\n",
    "m2_unimportant = coff_m2.sort_values('Importance', ascending=True).head(25)\n",
    "m2_unimportant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these features have literally no importance on this Random Forest Regressor. We will use these later to drop from the features so that we can build a model that works with the important features only and doesn't waste time on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Random Forest 1', 'MAE':m2_MAE, 'MSE':m2_MSE, 'RMSE':m2_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dummy Model (average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8158008483225205"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy model is the average\n",
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29065108266816125"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assume the model is the average of the training data (we know this value)\n",
    "y_pred_dm = np.full(y_test.size, y_train.mean())\n",
    "# Mean Absolute Error\n",
    "m3_MAE = mean_absolute_error(y_test, y_pred_dm)\n",
    "m3_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14451655741084168"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m3_MSE = mean_squared_error(y_test, y_pred_dm)\n",
    "m3_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38015333407829227"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m3_RMSE = m3_MSE**0.5\n",
    "m3_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are worse than the Random Forest Regressor, so that's a good thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11923361714123604"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference in root mean squared error between the two models\n",
    "diff = m3_RMSE - m2_RMSE\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.315932512657726"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lifetime dollar value of that difference\n",
    "10**diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is honestly not that impressive, but is still better than the dummy model, but that is considering that difference near 0 on the log scale. Since the log scale is exponential, that difference is much greater even near the mean. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.67260325601194"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_mean = 10**(y_train.mean() + diff) - 10**y_train.mean()\n",
    "diff_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can use those results to improve the models after we try the Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform = perform.append({'Model':'Dummy Model (average)', 'MAE':m3_MAE, 'MSE':m3_MSE, 'RMSE':m3_RMSE}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.184755203593603"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor\n",
    "reg_gb = GradientBoostingRegressor(min_samples_leaf=40, random_state=0)\n",
    "# fit the regressor\n",
    "model_gb = reg_gb.fit(X_train,y_train)\n",
    "# use regressor to predict on test data\n",
    "y_pred_gb = regr.predict(X_test)\n",
    "# compare test data for a score - Mean Absolute Error\n",
    "m4_MAE = mean_absolute_error(y_test, y_pred_gb)\n",
    "m4_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06807909868651355"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error\n",
    "m4_MSE = mean_squared_error(y_test, y_pred_gb)\n",
    "m4_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26091971693705623"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root mean squared error\n",
    "m4_RMSE = m4_MSE**0.5\n",
    "m4_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are extremely good; they are very similar to the results from the Random Forest Regressor. We probably should improve these two models to get the best results. Let's look at the importance of each feature in the GB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_total</th>\n",
       "      <td>0.490292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_tot_lg</th>\n",
       "      <td>0.456609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>November</th>\n",
       "      <td>0.010038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356615</th>\n",
       "      <td>0.006983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294517</th>\n",
       "      <td>0.003973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_items</th>\n",
       "      <td>0.003904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457101</th>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1011</th>\n",
       "      <td>0.002509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July</th>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>December</th>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>September</th>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>August</th>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>February</th>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1010</th>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost</th>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>June</th>\n",
       "      <td>0.001029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>October</th>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS10</th>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "first_total     0.490292\n",
       "first_tot_lg    0.456609\n",
       "November        0.010038\n",
       "1356615         0.006983\n",
       "294517          0.003973\n",
       "first_items     0.003904\n",
       "457101          0.002933\n",
       "BES1011         0.002509\n",
       "July            0.002429\n",
       "December        0.002158\n",
       "September       0.001842\n",
       "August          0.001454\n",
       "February        0.001301\n",
       "BES1010         0.001234\n",
       "custom          0.001187\n",
       "other           0.001159\n",
       "boost           0.001090\n",
       "June            0.001029\n",
       "October         0.000958\n",
       "ROUTEINS10      0.000945"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the most important features\n",
    "coff_m4 = pd.DataFrame(model_gb.feature_importances_, X.columns, columns=['Importance'])\n",
    "coff_m4.sort_values('Importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEM1007</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optonline.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlook.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rocketmail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbcglobal.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verizon.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windstream.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ymail.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES3003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES1005</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580111</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6738</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6737</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6729</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6728</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msn.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM1009</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>live.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aim.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aol.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>att.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charter.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bellsouth.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comcast.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEINS18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthlink.net</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BES5001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icloud.com</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEM6008</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Importance\n",
       "BEM1007                0.0\n",
       "optonline.net          0.0\n",
       "outlook.com            0.0\n",
       "rocketmail.com         0.0\n",
       "sbcglobal.net          0.0\n",
       "vendor                 0.0\n",
       "verizon.net            0.0\n",
       "windstream.net         0.0\n",
       "ymail.com              0.0\n",
       "BES3003                0.0\n",
       "BES1005                0.0\n",
       "412739                 0.0\n",
       "580111                 0.0\n",
       "BEM6739                0.0\n",
       "BEM6738                0.0\n",
       "BEM6737                0.0\n",
       "BEM6729                0.0\n",
       "BEM6728                0.0\n",
       "msn.com                0.0\n",
       "BEM1009                0.0\n",
       "me.com                 0.0\n",
       "live.com               0.0\n",
       "Saturday               0.0\n",
       "Friday                 0.0\n",
       "ROUTEINS22             0.0\n",
       "aim.com                0.0\n",
       "aol.com                0.0\n",
       "att.net                0.0\n",
       "mac.com                0.0\n",
       "charter.net            0.0\n",
       "bellsouth.net          0.0\n",
       "comcast.net            0.0\n",
       "ROUTEINS19             0.0\n",
       "ROUTEINS18             0.0\n",
       "earthlink.net          0.0\n",
       "BES5001                0.0\n",
       "hold                   0.0\n",
       "icloud.com             0.0\n",
       "BEM6008                0.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the LEAST important features and eliminate those features from the X data set; then run the models again\n",
    "m4_unimportant = coff_m4.sort_values('Importance', ascending=True).head(39)\n",
    "m4_unimportant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these features have literally no importance on this Gradient Boosting Regressor. We will use these to drop the features so that we can build a model that works with the important features only and doesn't waste time on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression 1</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "0    Linear Regression 1  1.041380e+10  4.308612e+23  6.564002e+11"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append({'Model':'Gradient Boost 1', 'MAE':m4_MAE, 'MSE':m4_MSE, 'RMSE':m4_RMSE}, ignore_index=True)\n",
    "perform.sort_values('MSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Remove unimportant features\n",
    "The results from the first round of modeling were good, but there was a lot of unimportant features that were still considered by the models. Let's eliminate those features and see if we the models perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the unimportant features found in either GB or RF and then we try to run the same models again. We will try a few different models: <br>\n",
    "- Linear Regression\n",
    "- Random Forest Regressor\n",
    "- Gradient Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_total</th>\n",
       "      <th>Marketing_first</th>\n",
       "      <th>first_items</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>first_tot_lg</th>\n",
       "      <th>boost</th>\n",
       "      <th>custom</th>\n",
       "      <th>gmail.com</th>\n",
       "      <th>hotmail.com</th>\n",
       "      <th>yahoo.com</th>\n",
       "      <th>...</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.163102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.138461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.98</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.447158</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39766</th>\n",
       "      <td>27.98</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.446848</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39767</th>\n",
       "      <td>59.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.777934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39768</th>\n",
       "      <td>54.97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.740126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>90.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.957512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39730 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_total  Marketing_first  first_items  Vendor  first_tot_lg  boost  \\\n",
       "1           145.58                1            2     1.0      2.163102      1   \n",
       "2           137.55                0            5     1.0      2.138461      1   \n",
       "3            22.98                1            2     1.0      1.361350      1   \n",
       "4            28.00                0            1     0.0      1.447158      1   \n",
       "5            12.00                1            1     0.0      1.079181      1   \n",
       "...            ...              ...          ...     ...           ...    ...   \n",
       "39766        27.98                0            2     1.0      1.446848      1   \n",
       "39767        59.97                0            2     1.0      1.777934      1   \n",
       "39768        54.97                1            2     1.0      1.740126      1   \n",
       "39769        90.68                0            3     1.0      1.957512      1   \n",
       "39770        25.00                0            1     0.0      1.397940      1   \n",
       "\n",
       "       custom  gmail.com  hotmail.com  yahoo.com  ...  December  February  \\\n",
       "1           1          0            0          0  ...         0         0   \n",
       "2           1          0            0          0  ...         0         0   \n",
       "3           1          0            0          0  ...         0         0   \n",
       "4           1          0            0          0  ...         0         0   \n",
       "5           1          0            0          0  ...         0         0   \n",
       "...       ...        ...          ...        ...  ...       ...       ...   \n",
       "39766       0          1            0          0  ...         0         0   \n",
       "39767       0          1            0          0  ...         0         0   \n",
       "39768       0          1            0          0  ...         0         0   \n",
       "39769       0          1            0          0  ...         0         0   \n",
       "39770       0          1            0          0  ...         0         0   \n",
       "\n",
       "       January  July  June  March  May  November  October  September  \n",
       "1            0     0     0      0    0         1        0          0  \n",
       "2            0     0     0      0    0         1        0          0  \n",
       "3            0     0     0      0    0         1        0          0  \n",
       "4            0     0     0      0    0         0        0          0  \n",
       "5            0     0     0      0    0         0        0          0  \n",
       "...        ...   ...   ...    ...  ...       ...      ...        ...  \n",
       "39766        0     0     0      0    0         0        0          1  \n",
       "39767        0     0     0      0    0         0        0          1  \n",
       "39768        0     0     0      0    0         0        0          1  \n",
       "39769        0     0     0      0    0         0        0          1  \n",
       "39770        0     0     0      0    0         0        0          1  \n",
       "\n",
       "[39730 rows x 42 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the unimportant features\n",
    "unimport = list(set(m4_unimportant.index.tolist()) | set(m2_unimportant.index.tolist()))\n",
    "# remove unimportant features from Gradient Boosting\n",
    "X1 = X.drop(unimport, axis=1)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That eliminated a lot of features and took us down to just 40 features! Excellent! <br>\n",
    "<br>\n",
    "Let's model with those features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8158008483225205, 1.8162965793223824)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's scale the X values\n",
    "scaler1 = preprocessing.StandardScaler().fit(X1)\n",
    "X1_scaled=scaler1.transform(X1)\n",
    "\n",
    "# split the X and y values again\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1_scaled, y, test_size=0.20, random_state=1)\n",
    "# check the mean values of the y to make sure this is a good split\n",
    "y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Linear regression on reduced feature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try standard linear regression on the data set with less features\n",
    "lm5 = linear_model.LinearRegression()\n",
    "model5 = lm5.fit(X1_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted results from the first model on the X_test values\n",
    "y5_pred = model5.predict(X1_test)\n",
    "# Mean Absolute Error\n",
    "m5_MAE = mean_absolute_error(y_test, y5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "m5_MSE = mean_squared_error(y_test, y5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Squared Error\n",
    "m5_RMSE = m5_MSE**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression 1</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "4    Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "0    Linear Regression 1  1.041380e+10  4.308612e+23  6.564002e+11"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append({'Model':'Linear Regression 2', 'MAE':m5_MAE, 'MSE':m5_MSE, 'RMSE':m5_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This updated version of linear regression actually performed better than the first attempt at Random Forest Regression or Gradient Boost Regression. That's great to see that eliminating those features lead to such improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Random Forest Regression with reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a minimum sample of 40 or 1/1000th of the total number of customers\n",
    "regr1 = RandomForestRegressor(min_samples_leaf=40, random_state=33)\n",
    "model1_rf = regr.fit(X1_train,y_train)\n",
    "y_pred1_rf = regr.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "4    Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "5        Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "0      Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "m6_MAE = mean_absolute_error(y_test, y_pred1_rf)\n",
    "# Mean Squared Error\n",
    "m6_MSE = mean_squared_error(y_test, y_pred1_rf)\n",
    "# root mean squared error\n",
    "m6_RMSE = m6_MSE**0.5\n",
    "# add to performance DF\n",
    "perform = perform.append({'Model':'Random Forest 2', 'MAE':m6_MAE, 'MSE':m6_MSE, 'RMSE':m6_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these values look good, but similar to previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gradient Boost with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "4    Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "5        Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01\n",
       "6       Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "0      Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor\n",
    "reg1_gb = GradientBoostingRegressor(min_samples_leaf=40, random_state=0)\n",
    "model1_gb = reg_gb.fit(X1_train,y_train)\n",
    "# use regressor to predict on test data\n",
    "y_pred1_gb = regr.predict(X1_test)\n",
    "# compare test data for a score - Mean Absolute Error\n",
    "m7_MAE = mean_absolute_error(y_test, y_pred1_gb)\n",
    "# Mean Squared Error\n",
    "m7_MSE = mean_squared_error(y_test, y_pred1_gb)\n",
    "# root mean squared error\n",
    "m7_RMSE = m7_MSE**0.5\n",
    "perform = perform.append({'Model':'Gradient Boost 2', 'MAE':m7_MAE, 'MSE':m7_MSE, 'RMSE':m7_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look like great models (except for the first Linear Regression). Let's try XGBoost model next before moving on to hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>4.628376e-01</td>\n",
       "      <td>3.046849e-01</td>\n",
       "      <td>5.519827e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE\n",
       "4    Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01\n",
       "5        Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01\n",
       "6       Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01\n",
       "7       X Gradient Boost  4.628376e-01  3.046849e-01  5.519827e-01\n",
       "0      Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate the XGB Regressor\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "# fit the model\n",
    "xg_reg.fit(X1_train,y_train)\n",
    "# predict on the model\n",
    "y_pred1_xgb = xg_reg.predict(X1_test)\n",
    "# get scores of the model\n",
    "m8_MAE = mean_absolute_error(y_test, y_pred1_xgb)\n",
    "m8_MSE = mean_squared_error(y_test, y_pred1_xgb)\n",
    "m8_RMSE = m8_MSE**0.5\n",
    "perform = perform.append({'Model':'X Gradient Boost', 'MAE':m8_MAE, 'MSE':m8_MSE, 'RMSE':m8_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost performed worse than the other models; maybe it's possible to Let's see if tuning the hyperparameters can make them better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took a guess at a good hyperparameter of 40 for the minimum number of leaves per node. That looked like a good start relative to the Linear Regression results. Instead, we should also consider multiple values for the hyperparameter for both the Gradient Boost and Random Forest Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.068421</td>\n",
       "      <td>0.261575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>115</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.261669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>134</td>\n",
       "      <td>0.187082</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>0.261838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>159</td>\n",
       "      <td>0.187473</td>\n",
       "      <td>0.068676</td>\n",
       "      <td>0.262060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>176</td>\n",
       "      <td>0.187689</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.262203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>206</td>\n",
       "      <td>0.188195</td>\n",
       "      <td>0.068873</td>\n",
       "      <td>0.262437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>232</td>\n",
       "      <td>0.188576</td>\n",
       "      <td>0.068982</td>\n",
       "      <td>0.262645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>279</td>\n",
       "      <td>0.189011</td>\n",
       "      <td>0.069079</td>\n",
       "      <td>0.262828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>387</td>\n",
       "      <td>0.190149</td>\n",
       "      <td>0.069434</td>\n",
       "      <td>0.263504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>442</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.263906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>517</td>\n",
       "      <td>0.191253</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.264233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>553</td>\n",
       "      <td>0.191384</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.264364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>616</td>\n",
       "      <td>0.191610</td>\n",
       "      <td>0.069940</td>\n",
       "      <td>0.264461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>625</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.069958</td>\n",
       "      <td>0.264496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>632</td>\n",
       "      <td>0.191721</td>\n",
       "      <td>0.069972</td>\n",
       "      <td>0.264523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>756</td>\n",
       "      <td>0.192431</td>\n",
       "      <td>0.070285</td>\n",
       "      <td>0.265113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>879</td>\n",
       "      <td>0.192539</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.265296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>894</td>\n",
       "      <td>0.192514</td>\n",
       "      <td>0.070395</td>\n",
       "      <td>0.265320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>893</td>\n",
       "      <td>0.192521</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.265324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>965</td>\n",
       "      <td>0.192768</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.265684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Node_size       MAE       MSE      RMSE\n",
       "18  Random Forest       100  0.186482  0.068421  0.261575\n",
       "15  Random Forest       115  0.186776  0.068471  0.261669\n",
       "0   Random Forest       134  0.187082  0.068559  0.261838\n",
       "9   Random Forest       159  0.187473  0.068676  0.262060\n",
       "16  Random Forest       176  0.187689  0.068750  0.262203\n",
       "6   Random Forest       206  0.188195  0.068873  0.262437\n",
       "8   Random Forest       232  0.188576  0.068982  0.262645\n",
       "14  Random Forest       279  0.189011  0.069079  0.262828\n",
       "13  Random Forest       387  0.190149  0.069434  0.263504\n",
       "5   Random Forest       442  0.190785  0.069646  0.263906\n",
       "4   Random Forest       517  0.191253  0.069819  0.264233\n",
       "1   Random Forest       553  0.191384  0.069888  0.264364\n",
       "10  Random Forest       616  0.191610  0.069940  0.264461\n",
       "17  Random Forest       625  0.191670  0.069958  0.264496\n",
       "2   Random Forest       632  0.191721  0.069972  0.264523\n",
       "11  Random Forest       756  0.192431  0.070285  0.265113\n",
       "19  Random Forest       879  0.192539  0.070382  0.265296\n",
       "3   Random Forest       894  0.192514  0.070395  0.265320\n",
       "12  Random Forest       893  0.192521  0.070397  0.265324\n",
       "7   Random Forest       965  0.192768  0.070588  0.265684"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "node_size = random.sample(range(10,1000), 20)\n",
    "\n",
    "perform_h = pd.DataFrame(columns=['Model', 'Node_size', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# loops through the number of leaves\n",
    "for n in node_size:\n",
    "    reg_h = RandomForestRegressor(min_samples_leaf=n, random_state=33)\n",
    "    model_rf_h = reg_h.fit(X1_train,y_train)\n",
    "    y_pred1_rf_h = reg_h.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred1_rf_h)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred1_rf_h)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_h = perform_h.append({'Model':'Random Forest', 'Node_size':n, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_h.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These all look extremely similiar, let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_h['Node_size'], perform_h['RMSE'])\n",
    "plt.xlabel('Minimum Node size')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks like it trends downwards with smaller minimum node size, as it's allowed to fit the model more closely to the data. Let's try a different range of values to select from and iterate one more time on that hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.260739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183972</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.260755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.184057</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>0.260774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.184104</td>\n",
       "      <td>0.068008</td>\n",
       "      <td>0.260783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.183768</td>\n",
       "      <td>0.068012</td>\n",
       "      <td>0.260790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.183886</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.183686</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.260801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.183530</td>\n",
       "      <td>0.068024</td>\n",
       "      <td>0.260814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.260821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.183772</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>0.260831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.183665</td>\n",
       "      <td>0.068039</td>\n",
       "      <td>0.260842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183516</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>0.260872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.183342</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.261063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.068228</td>\n",
       "      <td>0.261205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.182952</td>\n",
       "      <td>0.068289</td>\n",
       "      <td>0.261322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182863</td>\n",
       "      <td>0.068381</td>\n",
       "      <td>0.261498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>0.186482</td>\n",
       "      <td>0.068421</td>\n",
       "      <td>0.261575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>115</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.261669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.182736</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>0.261672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>134</td>\n",
       "      <td>0.187082</td>\n",
       "      <td>0.068559</td>\n",
       "      <td>0.261838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.182726</td>\n",
       "      <td>0.068671</td>\n",
       "      <td>0.262051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>159</td>\n",
       "      <td>0.187473</td>\n",
       "      <td>0.068676</td>\n",
       "      <td>0.262060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>176</td>\n",
       "      <td>0.187689</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.262203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.182776</td>\n",
       "      <td>0.068873</td>\n",
       "      <td>0.262437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>206</td>\n",
       "      <td>0.188195</td>\n",
       "      <td>0.068873</td>\n",
       "      <td>0.262437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>232</td>\n",
       "      <td>0.188576</td>\n",
       "      <td>0.068982</td>\n",
       "      <td>0.262645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>279</td>\n",
       "      <td>0.189011</td>\n",
       "      <td>0.069079</td>\n",
       "      <td>0.262828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>387</td>\n",
       "      <td>0.190149</td>\n",
       "      <td>0.069434</td>\n",
       "      <td>0.263504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>442</td>\n",
       "      <td>0.190785</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.263906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.183144</td>\n",
       "      <td>0.069658</td>\n",
       "      <td>0.263928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>517</td>\n",
       "      <td>0.191253</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.264233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>553</td>\n",
       "      <td>0.191384</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.264364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>616</td>\n",
       "      <td>0.191610</td>\n",
       "      <td>0.069940</td>\n",
       "      <td>0.264461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>625</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.069958</td>\n",
       "      <td>0.264496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>632</td>\n",
       "      <td>0.191721</td>\n",
       "      <td>0.069972</td>\n",
       "      <td>0.264523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>756</td>\n",
       "      <td>0.192431</td>\n",
       "      <td>0.070285</td>\n",
       "      <td>0.265113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>879</td>\n",
       "      <td>0.192539</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.265296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>894</td>\n",
       "      <td>0.192514</td>\n",
       "      <td>0.070395</td>\n",
       "      <td>0.265320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>893</td>\n",
       "      <td>0.192521</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.265324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>965</td>\n",
       "      <td>0.192768</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.265684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Node_size       MAE       MSE      RMSE\n",
       "36  Random Forest Tune 1        26  0.183902  0.067985  0.260739\n",
       "35  Random Forest Tune 1        27  0.183972  0.067993  0.260755\n",
       "34  Random Forest Tune 1        28  0.184057  0.068003  0.260774\n",
       "33  Random Forest Tune 1        29  0.184104  0.068008  0.260783\n",
       "39  Random Forest Tune 1        23  0.183768  0.068012  0.260790\n",
       "27  Random Forest Tune 1        25  0.183886  0.068017  0.260800\n",
       "21  Random Forest Tune 1        21  0.183686  0.068017  0.260801\n",
       "25  Random Forest Tune 1        19  0.183530  0.068024  0.260814\n",
       "23  Random Forest Tune 1        24  0.183825  0.068027  0.260821\n",
       "22  Random Forest Tune 1        22  0.183772  0.068033  0.260831\n",
       "20  Random Forest Tune 1        20  0.183665  0.068039  0.260842\n",
       "37  Random Forest Tune 1        18  0.183516  0.068054  0.260872\n",
       "24  Random Forest Tune 1        15  0.183342  0.068154  0.261063\n",
       "28  Random Forest Tune 1        12  0.183076  0.068228  0.261205\n",
       "32  Random Forest Tune 1        11  0.182952  0.068289  0.261322\n",
       "38  Random Forest Tune 1        10  0.182863  0.068381  0.261498\n",
       "18         Random Forest       100  0.186482  0.068421  0.261575\n",
       "15         Random Forest       115  0.186776  0.068471  0.261669\n",
       "30  Random Forest Tune 1         9  0.182736  0.068472  0.261672\n",
       "0          Random Forest       134  0.187082  0.068559  0.261838\n",
       "31  Random Forest Tune 1         8  0.182726  0.068671  0.262051\n",
       "9          Random Forest       159  0.187473  0.068676  0.262060\n",
       "16         Random Forest       176  0.187689  0.068750  0.262203\n",
       "26  Random Forest Tune 1         7  0.182776  0.068873  0.262437\n",
       "6          Random Forest       206  0.188195  0.068873  0.262437\n",
       "8          Random Forest       232  0.188576  0.068982  0.262645\n",
       "14         Random Forest       279  0.189011  0.069079  0.262828\n",
       "13         Random Forest       387  0.190149  0.069434  0.263504\n",
       "5          Random Forest       442  0.190785  0.069646  0.263906\n",
       "29  Random Forest Tune 1         5  0.183144  0.069658  0.263928\n",
       "4          Random Forest       517  0.191253  0.069819  0.264233\n",
       "1          Random Forest       553  0.191384  0.069888  0.264364\n",
       "10         Random Forest       616  0.191610  0.069940  0.264461\n",
       "17         Random Forest       625  0.191670  0.069958  0.264496\n",
       "2          Random Forest       632  0.191721  0.069972  0.264523\n",
       "11         Random Forest       756  0.192431  0.070285  0.265113\n",
       "19         Random Forest       879  0.192539  0.070382  0.265296\n",
       "3          Random Forest       894  0.192514  0.070395  0.265320\n",
       "12         Random Forest       893  0.192521  0.070397  0.265324\n",
       "7          Random Forest       965  0.192768  0.070588  0.265684"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much smaller minimum node size \n",
    "node_size = random.sample(range(5,30), 20)\n",
    "\n",
    "# we'll add on to the existing DF so we get a better look at the full curve\n",
    "\n",
    "# loops through the number of leaves\n",
    "for n in node_size:\n",
    "    reg_h = RandomForestRegressor(min_samples_leaf=n, random_state=33)\n",
    "    model_rf_h = reg_h.fit(X1_train,y_train)\n",
    "    y_pred1_rf_h = reg_h.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred1_rf_h)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred1_rf_h)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_h = perform_h.append({'Model':'Random Forest Tune 1', 'Node_size':n, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_h.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_h['Node_size'], perform_h['RMSE'])\n",
    "plt.xlabel('Minimum Node size')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the dip that I wanted to see to consider a balance between under and over-fitting to the data. Let's find the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Node_size</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.183902</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>0.260739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.183972</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.260755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.184057</td>\n",
       "      <td>0.068003</td>\n",
       "      <td>0.260774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.184104</td>\n",
       "      <td>0.068008</td>\n",
       "      <td>0.260783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.183768</td>\n",
       "      <td>0.068012</td>\n",
       "      <td>0.260790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.183886</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.183686</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.260801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.183530</td>\n",
       "      <td>0.068024</td>\n",
       "      <td>0.260814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.183825</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.260821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.183772</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>0.260831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Node_size       MAE       MSE      RMSE\n",
       "36  Random Forest Tune 1        26  0.183902  0.067985  0.260739\n",
       "35  Random Forest Tune 1        27  0.183972  0.067993  0.260755\n",
       "34  Random Forest Tune 1        28  0.184057  0.068003  0.260774\n",
       "33  Random Forest Tune 1        29  0.184104  0.068008  0.260783\n",
       "39  Random Forest Tune 1        23  0.183768  0.068012  0.260790\n",
       "27  Random Forest Tune 1        25  0.183886  0.068017  0.260800\n",
       "21  Random Forest Tune 1        21  0.183686  0.068017  0.260801\n",
       "25  Random Forest Tune 1        19  0.183530  0.068024  0.260814\n",
       "23  Random Forest Tune 1        24  0.183825  0.068027  0.260821\n",
       "22  Random Forest Tune 1        22  0.183772  0.068033  0.260831"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_h.sort_values('RMSE', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 26 is the best minimum node size for Random Forest Regression with this data. We'll add this to the overall performance dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Node_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>1.839021e-01</td>\n",
       "      <td>6.798485e-02</td>\n",
       "      <td>2.607391e-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>4.628376e-01</td>\n",
       "      <td>3.046849e-01</td>\n",
       "      <td>5.519827e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model           MAE           MSE          RMSE Node_size\n",
       "4    Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01       NaN\n",
       "8   Random Forest Tune 1  1.839021e-01  6.798485e-02  2.607391e-01        26\n",
       "1        Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01       NaN\n",
       "3       Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01       NaN\n",
       "5        Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01       NaN\n",
       "6       Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01       NaN\n",
       "2  Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01       NaN\n",
       "7       X Gradient Boost  4.628376e-01  3.046849e-01  5.519827e-01       NaN\n",
       "0      Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11       NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append(perform_h.sort_values('RMSE', ascending=True).head(1), ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned RF did perform slightly better than the previous implementations of random forest, but still not as good as the 2nd attempt at Linear Regression. Let's try to tune the Gradient Boosting next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Gradient Boosting with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same hyperparameter tuning, but with Gradient Boosting. Learning Rate is the most important parameter in GB, so we'll tune that throughout the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.386675</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.190392</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.186822</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.220271</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.231161</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.053926</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.022280</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.282555</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.313403</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Learning_rate       MAE       MSE      RMSE\n",
       "0   Gradient Boost       0.386675  0.184716  0.068098  0.260956\n",
       "17  Gradient Boost       0.190392  0.184716  0.068098  0.260956\n",
       "16  Gradient Boost       0.186822  0.184716  0.068098  0.260956\n",
       "15  Gradient Boost       0.220271  0.184716  0.068098  0.260956\n",
       "14  Gradient Boost       0.231161  0.184716  0.068098  0.260956\n",
       "13  Gradient Boost       0.053926  0.184716  0.068098  0.260956\n",
       "12  Gradient Boost       0.022280  0.184716  0.068098  0.260956\n",
       "11  Gradient Boost       0.282555  0.184716  0.068098  0.260956\n",
       "10  Gradient Boost       0.008016  0.184716  0.068098  0.260956\n",
       "9   Gradient Boost       0.313403  0.184716  0.068098  0.260956"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much smaller minimum node size \n",
    "learn_rt = [random.random()*0.4 for x in range(20)]\n",
    "\n",
    "# we'll add on to the existing DF so we get a better look at the full curve\n",
    "perform_gb = pd.DataFrame(columns=['Model', 'Learning_rate', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# loops through the number of leaves\n",
    "for r in learn_rt:\n",
    "    reg_gb = GradientBoostingRegressor(learning_rate=r, random_state=0)\n",
    "    model_gb = reg_gb.fit(X1_train,y_train)\n",
    "    # use regressor to predict on test data\n",
    "    y_pred_gb = regr.predict(X1_test)\n",
    "    # Mean Absolute Error\n",
    "    MAE1 = mean_absolute_error(y_test, y_pred_gb)\n",
    "    # Mean Squared Error\n",
    "    MSE1 = mean_squared_error(y_test, y_pred_gb)\n",
    "    # root mean squared error\n",
    "    RMSE1 = MSE1**0.5\n",
    "    # add to performance DF\n",
    "    perform_gb = perform_gb.append({'Model':'Gradient Boost', 'Learning_rate':r, 'MAE':MAE1, 'MSE': MSE1, 'RMSE':RMSE1}, ignore_index=True)\n",
    "\n",
    "perform_gb.sort_values('RMSE', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the minimum node size versus the RSME\n",
    "plt.scatter(perform_gb['Learning_rate'], perform_gb['RMSE'])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('RSME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the results are pretty much exactly as we planned them to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. More Extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we did some hyperparameter tuning, but this was just using a random search of one parameter. It may not even be the best parameter to tune. Instead, we will focus on doing a more extensive search in this section. We will form a grid for both Random Forest and Gradient Boosting. We will then using random search to pick out some points on that grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Random Forest Regression with more extensive Hyperparameter Tuning (using multiple hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [5, 10, 26, 40], 'min_samples_leaf': [5, 10, 26, 40], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "### create the grid of hyperparameters to use\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 26, 40]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [5, 10, 26, 40]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 103.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 206.1min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 296.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [5, 10, 26, 40],\n",
       "                                        'min_samples_split': [5, 10, 26, 40],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=33, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run the random search of that grid that we just created\n",
    "\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 150, cv = 3, verbose=2, random_state=33, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X1_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 26,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=5,\n",
       "                      min_samples_split=26, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=600, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18477567674145426, 0.06767429829575794, 0.2609559220699036)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how these parameters performed\n",
    "# rf_h = RandomForestRegressor(rf_random.best_params_)\n",
    "model_rf_h = rf_random.best_estimator_\n",
    "y_pred_h_rf = model_rf_h.predict(X1_test)\n",
    "\n",
    "# let's see the error\n",
    "# Mean Absolute Error\n",
    "rf_h_MAE = mean_absolute_error(y_test, y_pred_h_rf)\n",
    "# Mean Squared Error\n",
    "rf_h_MSE = mean_squared_error(y_test, y_pred_h_rf)\n",
    "# root mean squared error\n",
    "rf_h_RMSE = m6_MSE**0.5\n",
    "\n",
    "# display\n",
    "rf_h_MAE, rf_h_MSE, rf_h_RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is barely any different the the resutls we got from the values we had previously, but I will still use those values in future Random Forest Models with this data. Let's add it to the performance dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Node_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>1.839021e-01</td>\n",
       "      <td>6.798485e-02</td>\n",
       "      <td>2.607391e-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Hyper Tune</td>\n",
       "      <td>1.847757e-01</td>\n",
       "      <td>6.767430e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>4.628376e-01</td>\n",
       "      <td>3.046849e-01</td>\n",
       "      <td>5.519827e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model           MAE           MSE          RMSE  \\\n",
       "4       Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01   \n",
       "8      Random Forest Tune 1  1.839021e-01  6.798485e-02  2.607391e-01   \n",
       "1           Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "3          Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "5           Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "6          Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "9  Random Forest Hyper Tune  1.847757e-01  6.767430e-02  2.609559e-01   \n",
       "2     Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01   \n",
       "7          X Gradient Boost  4.628376e-01  3.046849e-01  5.519827e-01   \n",
       "0         Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11   \n",
       "\n",
       "  Node_size  \n",
       "4       NaN  \n",
       "8        26  \n",
       "1       NaN  \n",
       "3       NaN  \n",
       "5       NaN  \n",
       "6       NaN  \n",
       "9       NaN  \n",
       "2       NaN  \n",
       "7       NaN  \n",
       "0       NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform = perform.append({'Model':'Random Forest Hyper Tune', 'MAE':rf_h_MAE, 'MSE':rf_h_MSE, 'RMSE':rf_h_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Grandient Boost Regression with more extensive Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not run this again unless you have a long time to do so. It took 11 hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'learning_rate': [0.0001, 0.001, 0.01, 0.02, 0.04, 0.08, 0.1, 0.2, 0.4], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10, 26, 40], 'min_samples_leaf': [1, 5, 10, 26, 40]}\n"
     ]
    }
   ],
   "source": [
    "### create the grid of hyperparameters to use\n",
    "\n",
    "# Number of estimators in XGBoost\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# learning rate\n",
    "learn_rt = [0.0001, 0.001, 0.01, 0.02, 0.04, 0.08, 0.1, 0.2, 0.4]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 26, 40]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 5, 10, 26, 40]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid_gb = {'n_estimators': n_estimators, 'learning_rate': learn_rt, 'max_features': max_features,'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf\n",
    "              }\n",
    "print(random_grid_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 59.4min\n",
      "C:\\Users\\sjrek\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 318.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 665.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_...\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.02, 0.04, 0.08, 0.1,\n",
       "                                                          0.2, 0.4],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 5, 10, 26, 40],\n",
       "                                        'min_samples_split': [2, 5, 10, 26, 40],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=33, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run the random search of that grid that we just created\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# First create the base model to tune\n",
    "gbr = GradientBoostingRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "gbr_random = RandomizedSearchCV(estimator = gbr, param_distributions = random_grid_gb, n_iter = 100, cv = 3, verbose=2, random_state=33, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "gbr_random.fit(X1_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 26,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.02}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best parameters\n",
    "gbr_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.02, loss='ls',\n",
       "                          max_depth=10, max_features='sqrt',\n",
       "                          max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                          min_impurity_split=None, min_samples_leaf=1,\n",
       "                          min_samples_split=26, min_weight_fraction_leaf=0.0,\n",
       "                          n_estimators=600, n_iter_no_change=None,\n",
       "                          presort='deprecated', random_state=None,\n",
       "                          subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best score\n",
    "gbr_random. best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1832013494353754, 0.06889463431642975, 0.2624778739559389)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how these parameters performed\n",
    "# rf_h = RandomForestRegressor(rf_random.best_params_)\n",
    "model_gb_h = gbr_random.best_estimator_\n",
    "y_pred_h_gb = model_gb_h.predict(X1_test)\n",
    "\n",
    "# let's see the error\n",
    "# Mean Absolute Error\n",
    "gb_h_MAE = mean_absolute_error(y_test, y_pred_h_gb)\n",
    "# Mean Squared Error\n",
    "gb_h_MSE = mean_squared_error(y_test, y_pred_h_gb)\n",
    "# root mean squared error\n",
    "gb_h_RMSE = gb_h_MSE**0.5\n",
    "\n",
    "# display\n",
    "gb_h_MAE, gb_h_MSE, gb_h_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Node_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>1.839021e-01</td>\n",
       "      <td>6.798485e-02</td>\n",
       "      <td>2.607391e-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Hyper Tune</td>\n",
       "      <td>1.847757e-01</td>\n",
       "      <td>6.767430e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boost Hyper Tune</td>\n",
       "      <td>1.832013e-01</td>\n",
       "      <td>6.889463e-02</td>\n",
       "      <td>2.624779e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>4.628376e-01</td>\n",
       "      <td>3.046849e-01</td>\n",
       "      <td>5.519827e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model           MAE           MSE          RMSE  \\\n",
       "4         Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01   \n",
       "8        Random Forest Tune 1  1.839021e-01  6.798485e-02  2.607391e-01   \n",
       "1             Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "3            Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "5             Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "6            Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "9    Random Forest Hyper Tune  1.847757e-01  6.767430e-02  2.609559e-01   \n",
       "10  Gradient Boost Hyper Tune  1.832013e-01  6.889463e-02  2.624779e-01   \n",
       "2       Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01   \n",
       "7            X Gradient Boost  4.628376e-01  3.046849e-01  5.519827e-01   \n",
       "0           Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11   \n",
       "\n",
       "   Node_size  \n",
       "4        NaN  \n",
       "8         26  \n",
       "1        NaN  \n",
       "3        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "9        NaN  \n",
       "10       NaN  \n",
       "2        NaN  \n",
       "7        NaN  \n",
       "0        NaN  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add these to the performance matrix\n",
    "perform = perform.append({'Model':'Gradient Boost Hyper Tune', 'MAE':gb_h_MAE, 'MSE':gb_h_MSE, 'RMSE':gb_h_RMSE}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good to see that hyperparameter tuning didn't help Gradient Boosting much. Linear Regression still appears to be the best model. <br>\n",
    "We should probably consider ensemble model with Linear Regression and using Random Forest on the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Ensemble Model (Linear Reg + RF Reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will combine the linear regression and then run random forest regressor on the residuals from that model. <br>\n",
    "<br>\n",
    "First, let's look at the linear regression model that worked the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.27507470e-02,  6.52388662e-03,  1.07481061e-02, -1.16284885e-02,\n",
       "        2.92708620e-01,  7.48977827e-04, -1.02071449e-02,  1.41956141e-03,\n",
       "       -5.95399298e-04,  1.02344482e-04, -1.11384863e-01, -9.19237413e-03,\n",
       "       -1.07327850e-01, -5.87714147e-03, -4.64873661e-03, -2.01483678e-03,\n",
       "        1.79383729e-03,  3.28907161e-03,  1.64012965e-03, -1.48998647e-02,\n",
       "        2.67575994e-03,  6.06264189e-03,  8.47365784e-03, -7.24565003e-03,\n",
       "        4.57960092e-03,  3.32887452e-03, -1.59305439e-03, -6.38759523e-04,\n",
       "        1.24217241e-03,  4.59810737e-04,  1.31171960e+10,  1.28299256e+10,\n",
       "        1.09480335e+10,  1.07970061e+10,  1.22077542e+10,  1.29888509e+10,\n",
       "        1.19122372e+10,  8.82386212e+09,  1.16685073e+10,  1.37022327e+10,\n",
       "        6.51969712e+09,  7.16153693e+09])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm5.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions on the test set\n",
    "forecast_train = lm5.predict(X1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals from that test set\n",
    "residual = y_train - forecast_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed residuals and x_train to RF Regressoor\n",
    "rf_res = RandomForestRegressor(min_samples_leaf=26)\n",
    "model11_rf = rf_res.fit(X1_train,residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ensemble of Linear regressor and RF regressor on test data\n",
    "res_pred11_rf = rf_res.predict(X1_test)\n",
    "forecast_m11 = lm5.predict(X1_test) + res_pred11_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Node_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ensemble Linear + RF</td>\n",
       "      <td>1.821710e-01</td>\n",
       "      <td>6.680951e-02</td>\n",
       "      <td>2.584753e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression 2</td>\n",
       "      <td>1.859726e-01</td>\n",
       "      <td>6.770457e-02</td>\n",
       "      <td>2.602010e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest Tune 1</td>\n",
       "      <td>1.839021e-01</td>\n",
       "      <td>6.798485e-02</td>\n",
       "      <td>2.607391e-01</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost 1</td>\n",
       "      <td>1.847552e-01</td>\n",
       "      <td>6.807910e-02</td>\n",
       "      <td>2.609197e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost 2</td>\n",
       "      <td>1.847164e-01</td>\n",
       "      <td>6.809799e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Hyper Tune</td>\n",
       "      <td>1.847757e-01</td>\n",
       "      <td>6.767430e-02</td>\n",
       "      <td>2.609559e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boost Hyper Tune</td>\n",
       "      <td>1.832013e-01</td>\n",
       "      <td>6.889463e-02</td>\n",
       "      <td>2.624779e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dummy Model (average)</td>\n",
       "      <td>2.906511e-01</td>\n",
       "      <td>1.445166e-01</td>\n",
       "      <td>3.801533e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>4.628376e-01</td>\n",
       "      <td>3.046849e-01</td>\n",
       "      <td>5.519827e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.041380e+10</td>\n",
       "      <td>4.308612e+23</td>\n",
       "      <td>6.564002e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model           MAE           MSE          RMSE  \\\n",
       "11       Ensemble Linear + RF  1.821710e-01  6.680951e-02  2.584753e-01   \n",
       "4         Linear Regression 2  1.859726e-01  6.770457e-02  2.602010e-01   \n",
       "8        Random Forest Tune 1  1.839021e-01  6.798485e-02  2.607391e-01   \n",
       "1             Random Forest 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "3            Gradient Boost 1  1.847552e-01  6.807910e-02  2.609197e-01   \n",
       "5             Random Forest 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "6            Gradient Boost 2  1.847164e-01  6.809799e-02  2.609559e-01   \n",
       "9    Random Forest Hyper Tune  1.847757e-01  6.767430e-02  2.609559e-01   \n",
       "10  Gradient Boost Hyper Tune  1.832013e-01  6.889463e-02  2.624779e-01   \n",
       "2       Dummy Model (average)  2.906511e-01  1.445166e-01  3.801533e-01   \n",
       "7            X Gradient Boost  4.628376e-01  3.046849e-01  5.519827e-01   \n",
       "0           Linear Regression  1.041380e+10  4.308612e+23  6.564002e+11   \n",
       "\n",
       "   Node_size  \n",
       "11       NaN  \n",
       "4        NaN  \n",
       "8         26  \n",
       "1        NaN  \n",
       "3        NaN  \n",
       "5        NaN  \n",
       "6        NaN  \n",
       "9        NaN  \n",
       "10       NaN  \n",
       "2        NaN  \n",
       "7        NaN  \n",
       "0        NaN  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate errors\n",
    "# Mean Absolute Error\n",
    "MAE11 = mean_absolute_error(y_test, forecast_m11)\n",
    "# Mean Squared Error\n",
    "MSE11 = mean_squared_error(y_test, forecast_m11)\n",
    "# root mean squared error\n",
    "RMSE11 = MSE11**0.5\n",
    "\n",
    "# append to the performance dataframe and print the DF to compare\n",
    "perform = perform.append({'Model':'Ensemble Linear + RF', 'MAE':MAE11, 'MSE':MSE11, 'RMSE':RMSE11}, ignore_index=True)\n",
    "perform.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That improved performance and looks like the best model to use for prediction of Customer Lifetime Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll validate those model scores, but doing a different test / train split. <br>\n",
    "The superior model should prevail no matter the split that was used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new performance dataframe to record scores\n",
    "valid = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8148540856161584, 1.8200836301478314)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redo the test / train split\n",
    "# let's scale the X values\n",
    "scaler1 = preprocessing.StandardScaler().fit(X1)\n",
    "X1_scaled=scaler1.transform(X1)\n",
    "\n",
    "# split the X and y values again - USING A DIFFERENT RANDOM STATE\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X1_scaled, y, test_size=0.20, random_state=33)\n",
    "# check the mean values of the y to make sure this is a good split\n",
    "y2_train.mean(), y2_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model       MAE       MSE      RMSE\n",
       "0  Linear Regression  0.185567  0.069419  0.263475"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the linear regression model\n",
    "lm12 = linear_model.LinearRegression()\n",
    "model12 = lm12.fit(X2_train,y2_train)\n",
    "# predicted results from the first model on the X_test values\n",
    "y12_pred = model12.predict(X2_test)\n",
    "\n",
    "# Mean Absolute Error\n",
    "MAE = mean_absolute_error(y2_test, y12_pred)\n",
    "# Mean Squared Error\n",
    "MSE = mean_squared_error(y2_test, y12_pred)\n",
    "# Root Mean Squared Error\n",
    "RMSE = MSE**0.5\n",
    "\n",
    "# add scores to new performance dataframe\n",
    "valid = valid.append({'Model':'Linear Regression', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}, ignore_index=True)\n",
    "valid.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble: Linear Reg + RF</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.261472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       MAE       MSE      RMSE\n",
       "1  Ensemble: Linear Reg + RF  0.182427  0.068368  0.261472\n",
       "0          Linear Regression  0.185567  0.069419  0.263475"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the ensemble linear + RF and count the score\n",
    "\n",
    "## make predictions on the test set\n",
    "forecast_train = lm12.predict(X2_train)\n",
    "# calculate residuals from that test set\n",
    "residual = y2_train - forecast_train\n",
    "# feed residuals and x_train to RF Regressoor\n",
    "rf_res_12 = RandomForestRegressor(min_samples_leaf=26)\n",
    "model12_rf = rf_res_12.fit(X2_train,residual)\n",
    "\n",
    "\n",
    "# use ensemble of Linear regressor and RF regressor on test data\n",
    "res_pred12_rf = rf_res_12.predict(X2_test)\n",
    "forecast_m12 = lm12.predict(X2_test) + res_pred12_rf\n",
    "\n",
    "# calculate errors\n",
    "# Mean Absolute Error\n",
    "MAE = mean_absolute_error(y2_test, forecast_m12)\n",
    "# Mean Squared Error\n",
    "MSE = mean_squared_error(y2_test, forecast_m12)\n",
    "# Root Mean Squared Error\n",
    "RMSE = MSE**0.5\n",
    "\n",
    "# add scores to new performance dataframe\n",
    "valid = valid.append({'Model':'Ensemble: Linear Reg + RF', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}, ignore_index=True)\n",
    "valid.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest n=26</td>\n",
       "      <td>0.184347</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble: Linear Reg + RF</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.261472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       MAE       MSE      RMSE\n",
       "2         Random Forest n=26  0.184347  0.069469  0.260956\n",
       "1  Ensemble: Linear Reg + RF  0.182427  0.068368  0.261472\n",
       "0          Linear Regression  0.185567  0.069419  0.263475"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the RF Tune 1\n",
    "regr13 = RandomForestRegressor(min_samples_leaf=26, random_state=33)\n",
    "model13_rf = regr13.fit(X2_train, y2_train)\n",
    "y_pred13_rf = regr13.predict(X2_test)\n",
    "\n",
    "# Mean Absolute Error\n",
    "MAE = mean_absolute_error(y2_test, y_pred13_rf)\n",
    "# Mean Squared Error\n",
    "MSE = mean_squared_error(y2_test, y_pred13_rf)\n",
    "# root mean squared error\n",
    "RMSE = m6_MSE**0.5\n",
    "\n",
    "# add scores to new performance dataframe\n",
    "valid = valid.append({'Model':'Random Forest n=26', 'MAE':MAE, 'MSE':MSE, 'RMSE':RMSE}, ignore_index=True)\n",
    "valid.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest n=26</td>\n",
       "      <td>0.184347</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble: Linear Reg + RF</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.261472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       MAE       MSE      RMSE\n",
       "2         Random Forest n=26  0.184347  0.069469  0.260956\n",
       "3             Gradient Boost  0.184716  0.068098  0.260956\n",
       "1  Ensemble: Linear Reg + RF  0.182427  0.068368  0.261472\n",
       "0          Linear Regression  0.185567  0.069419  0.263475"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the GB\n",
    "\n",
    "# create regressor\n",
    "reg14_gb = GradientBoostingRegressor(min_samples_leaf=40, random_state=0)\n",
    "model14_gb = reg14_gb.fit(X2_train, y2_train)\n",
    "# use regressor to predict on test data\n",
    "y_pred14_gb = reg14_gb.predict(X2_test)\n",
    "# compare test data for a score - Mean Absolute Error\n",
    "MAE = mean_absolute_error(y2_test, y_pred14_gb)\n",
    "# Mean Squared Error\n",
    "MSE = mean_squared_error(y2_test, y_pred14_gb)\n",
    "# root mean squared error\n",
    "RMSE = m7_MSE**0.5\n",
    "valid = valid.append({'Model':'Gradient Boost', 'MAE':m7_MAE, 'MSE':m7_MSE, 'RMSE':m7_RMSE}, ignore_index=True)\n",
    "valid.sort_values('RMSE', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest n=26</td>\n",
       "      <td>0.184347</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble: Linear Reg + RF</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.261472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>0.467911</td>\n",
       "      <td>0.311898</td>\n",
       "      <td>0.558478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       MAE       MSE      RMSE\n",
       "2         Random Forest n=26  0.184347  0.069469  0.260956\n",
       "3             Gradient Boost  0.184716  0.068098  0.260956\n",
       "1  Ensemble: Linear Reg + RF  0.182427  0.068368  0.261472\n",
       "0          Linear Regression  0.185567  0.069419  0.263475\n",
       "4           X Gradient Boost  0.467911  0.311898  0.558478"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run XGB\n",
    "\n",
    "# initiate the XGB Regressor\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "# fit the model\n",
    "xg_reg.fit(X2_train,y2_train)\n",
    "# predict on the model\n",
    "y_pred1_xgb = xg_reg.predict(X2_test)\n",
    "# get scores of the model\n",
    "m8_MAE = mean_absolute_error(y2_test, y_pred1_xgb)\n",
    "m8_MSE = mean_squared_error(y2_test, y_pred1_xgb)\n",
    "m8_RMSE = m8_MSE**0.5\n",
    "valid = valid.append({'Model':'X Gradient Boost', 'MAE':m8_MAE, 'MSE':m8_MSE, 'RMSE':m8_RMSE}, ignore_index=True)\n",
    "valid.sort_values('RMSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Ensemble model that performed the best with the previous test and train set did fairly well with the different train and test data. It still had the lowest MAE. Looks like a good model to choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble: Linear Reg + RF</td>\n",
       "      <td>0.182427</td>\n",
       "      <td>0.068368</td>\n",
       "      <td>0.261472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest n=26</td>\n",
       "      <td>0.184347</td>\n",
       "      <td>0.069469</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.184716</td>\n",
       "      <td>0.068098</td>\n",
       "      <td>0.260956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.185567</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.263475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X Gradient Boost</td>\n",
       "      <td>0.467911</td>\n",
       "      <td>0.311898</td>\n",
       "      <td>0.558478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       MAE       MSE      RMSE\n",
       "1  Ensemble: Linear Reg + RF  0.182427  0.068368  0.261472\n",
       "2         Random Forest n=26  0.184347  0.069469  0.260956\n",
       "3             Gradient Boost  0.184716  0.068098  0.260956\n",
       "0          Linear Regression  0.185567  0.069419  0.263475\n",
       "4           X Gradient Boost  0.467911  0.311898  0.558478"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.sort_values('MAE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I would go with that ensemble linear regression + random forest in boosted (sequential) fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.24341535e-01, 4.08321801e-01, 5.14046691e-01, 6.47146442e-01,\n",
       "       8.14709101e-01, 1.02565799e+00, 1.29122691e+00, 1.62555837e+00,\n",
       "       2.04645674e+00, 2.57633639e+00, 3.24341535e+00, 4.08321801e+00,\n",
       "       5.14046691e+00, 6.47146442e+00, 8.14709101e+00, 1.02565799e+01,\n",
       "       1.29122691e+01, 1.62555837e+01, 2.04645674e+01, 2.57633639e+01,\n",
       "       3.24341535e+01, 4.08321801e+01, 5.14046691e+01, 6.47146442e+01,\n",
       "       8.14709101e+01, 1.02565799e+02, 1.29122691e+02, 1.62555837e+02,\n",
       "       2.04645674e+02, 2.57633639e+02, 3.24341535e+02, 4.08321801e+02,\n",
       "       5.14046691e+02, 6.47146442e+02, 8.14709101e+02, 1.02565799e+03])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots the error as an exponential function\n",
    "x = np.array([0.1*i for i in range(36)])\n",
    "y1 = 10**x\n",
    "y2 = 10**(x+.122)\n",
    "difference = y2 - y1\n",
    "_ = plt.plot(x,difference)\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_total': -0.022750746996116573,\n",
       " 'Marketing_first': 0.006523886624658156,\n",
       " 'first_items': 0.010748106057485537,\n",
       " 'Vendor': -0.01162848848972585,\n",
       " 'first_tot_lg': 0.2927086197932447,\n",
       " 'boost': 0.0007489778265633023,\n",
       " 'custom': -0.010207144870600305,\n",
       " 'gmail.com': 0.0014195614103765179,\n",
       " 'hotmail.com': -0.000595399297693647,\n",
       " 'yahoo.com': 0.00010234448177038144,\n",
       " '1356615': -0.11138486338488328,\n",
       " '294517': -0.009192374133612737,\n",
       " 'web': -0.10732785039248068,\n",
       " 'BE523': -0.005877141467349583,\n",
       " 'BEM1003': -0.004648736613005582,\n",
       " 'BEM1006': -0.002014836777683056,\n",
       " 'BEM6001': 0.001793837288132328,\n",
       " 'BEM6003': 0.0032890716138842934,\n",
       " 'BEM6007': 0.001640129651457463,\n",
       " 'BES1006': -0.014899864747150849,\n",
       " 'BES1009': 0.0026757599399646025,\n",
       " 'BES1010': 0.006062641892770059,\n",
       " 'BES1011': 0.008473657843239295,\n",
       " 'ROUTEINS10': -0.0072456500313122126,\n",
       " 'other': 0.004579600921374914,\n",
       " 'Monday': 0.0033288745203481594,\n",
       " 'Sunday': -0.0015930543887089517,\n",
       " 'Thursday': -0.0006387595226665146,\n",
       " 'Tuesday': 0.0012421724149512727,\n",
       " 'Wednesday': 0.0004598107373862101,\n",
       " 'April': 13117195954.013851,\n",
       " 'August': 12829925625.63683,\n",
       " 'December': 10948033544.744184,\n",
       " 'February': 10797006062.442926,\n",
       " 'January': 12207754177.05144,\n",
       " 'July': 12988850859.504015,\n",
       " 'June': 11912237233.28915,\n",
       " 'March': 8823862124.017712,\n",
       " 'May': 11668507251.55702,\n",
       " 'November': 13702232688.078737,\n",
       " 'October': 6519697119.599128,\n",
       " 'September': 7161536929.89635}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at linear model for coefficients\n",
    "lin_coef = zip(X1.columns, lm5.coef_)\n",
    "dict(lin_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8164931301945546"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm5.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
